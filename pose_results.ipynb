{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "pose_results.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johansmm/RT-multiperson-pose-pytorch/blob/imt-atlantique/pose_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrjZTtw2rMCf"
      },
      "source": [
        "# Deep Learning project\n",
        "Intro by Tatiana"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiaLI5xU4EeM",
        "outputId": "f287b94c-d0a4-412c-8e67-084ee3ac7622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Libraries\n",
        "# Colab libraries\n",
        "from google.colab import drive\n",
        "from google.colab import output\n",
        "drive.mount('/content/gdrive')\n",
        "colab_path = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
        "\n",
        "# Basis libraries\n",
        "import os, re, sys, math, time, scipy, argparse\n",
        "import cv2, matplotlib\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from collections import OrderedDict\n",
        "from scipy.ndimage.morphology import generate_binary_structure\n",
        "from scipy.ndimage.filters import gaussian_filter, maximum_filter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1b25TcW4ik9"
      },
      "source": [
        "## Section 0: Download and install repository\n",
        "First, we will download the repository that we copied from the [original repository](https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation) in order to make some changes for educational purposes. Then, we install libraries and some dependences explained in the original repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKtbnvkHrBfA",
        "outputId": "aa95c7cc-eb90-426f-99ca-b96d52c1dc23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Independence install\n",
        "!sudo apt-get install swig\n",
        "%cd $colab_path\n",
        "if not os.path.isdir(\"RT-multiperson-pose-pytorch\"):\n",
        "  # Repository clone\n",
        "  !git clone https://github.com/Johansmm/RT-multiperson-pose-pytorch.git\n",
        "  %cd \"RT-multiperson-pose-pytorch\"\n",
        "  %cd lib/pafprocess \n",
        "  # Repository compile\n",
        "  !sh make.sh\n",
        "\n",
        "# Libraries install\n",
        "!python -m pip install -r ./requirements.txt\n",
        "!git submodule init && git submodule update\n",
        "%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n",
        "# Weights download\n",
        "if not os.path.isfile(\"./pose_model.pth\"):\n",
        "  !wget https://www.dropbox.com/s/ae071mfm2qoyc8v/pose_model.pth\n",
        "output.clear()\n",
        "print(\"[INFO]: Proyect uploaded successfully\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: Proyect uploaded successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXqO9ha9lQao",
        "outputId": "d93ee96c-259d-4e44-ff5c-8060fc3a5645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python demo/picture_demo.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bulding VGG19\n",
            "0.5459940652818991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNWcHBWR6K7n",
        "outputId": "8a8500c4-2697-46fa-ee18-789c798a1c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "# Framework libraries\n",
        "%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n",
        "sys.path.append('.')\n",
        "from lib.network.rtpose_vgg import get_model\n",
        "from lib.network import im_transform\n",
        "from lib.utils.common import Human, BodyPart, CocoPart, CocoColors, CocoPairsRender, draw_humans\n",
        "from lib.utils.paf_to_pose import paf_to_pose_cpp\n",
        "from lib.config import cfg, update_config\n",
        "from evaluate.coco_eval import get_outputs, handle_paf_and_heat\n",
        "data_download = False # For download COCO dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/RT-multiperson-pose-pytorch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--cfg CFG] [--weight WEIGHT] ...\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "174xVRPR9QN-"
      },
      "source": [
        "## Section 2: Replication of results\n",
        "In this section we replicated some resutls. First, we need download the data. For this case, we will use the `sh` compiler provided by [original repository](https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uBTojMrmtud"
      },
      "source": [
        "%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n",
        "if data_download and not os.path.isdir(\"data/coco\"):\n",
        "  !mkdir data\n",
        "  %cd data\n",
        "  !sh ../lib/datasets/CocoDataDownloader.sh\n",
        "  %cd $colab_path\"/RT-multiperson-pose-pytorch\"\n",
        "  output.clear()\n",
        "  print(\"[INFO]: Coco database downloaded successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MekeFPVJ2gKJ"
      },
      "source": [
        "Now, we defined some principal functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78deQRcV2mOz"
      },
      "source": [
        "%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n",
        "class Namespace:\n",
        "  def __init__(self, **kwargs):\n",
        "    self.__dict__.update(kwargs)\n",
        "\n",
        "def load_rtpose_model():\n",
        "  args = Namespace(cfg = './experiments/vgg19_368x368_sgd.yaml', weight = 'pose_model.pth', opts = [])\n",
        "  update_config(cfg, args)\n",
        "  model = get_model('vgg19')     \n",
        "  model.load_state_dict(torch.load(args.weight))\n",
        "  model = torch.nn.DataParallel(model).cuda()\n",
        "  model.float()\n",
        "  model.eval()\n",
        "  return model\n",
        "\n",
        "def im_forward(image, model):\n",
        "  with torch.no_grad():\n",
        "    paf, heatmap, im_scale = get_outputs(image, model, 'rtpose')\n",
        "  return paf, heatmap, im_scale\n",
        "\n",
        "model = load_rtpose_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYUR_206xALE"
      },
      "source": [
        "image = cv2.imread('./data/coco/images/training2017/000000000154.jpg')\n",
        "paf, heatmap, im_scale = im_forward(image, model)\n",
        "humans = paf_to_pose_cpp(heatmap, paf, cfg)\n",
        "for hum in humans:\n",
        "  print(dir(hum))\n",
        "\n",
        "out = draw_humans(image, humans)\n",
        "plt.imshow(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM88fGToxGPB",
        "outputId": "a85d1f4d-c9c0-4966-e880-9cfed231e9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Colab libraries\n",
        "from google.colab import drive\n",
        "from google.colab import output\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd \"/content/gdrive/My Drive/Colab Notebooks/RT-multiperson-pose-pytorch\"\n",
        "!git config --global user.email \"johan-steven.mejia-mogollon@imt-atlantique.com\"\n",
        "!git config --global user.name \"Johansmm\"\n",
        "!git remote set-url origin \"https://github.com/Johansmm/RT-multiperson-pose-pytorch.git\"\n",
        "# !git commit -am \"updating in colab\"\n",
        "# !git reset --hard\n",
        "!git pull origin imt-atlantique\n",
        "# !git push origin imt-atlantique"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/RT-multiperson-pose-pytorch\n",
            "On branch master\n",
            "Your branch is ahead of 'origin/master' by 24 commits.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "From https://github.com/Johansmm/RT-multiperson-pose-pytorch\n",
            " * branch            imt-atlantique -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOTNnyQsDfXb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}