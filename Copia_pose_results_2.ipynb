{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Copia_pose_results_2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"59a55a06af4c4105802e8ee7b82f1e09":{"model_module":"@jupyter-widgets/controls","model_name":"VideoModel","state":{"_view_name":"VideoView","_dom_classes":[],"_model_name":"VideoModel","format":"mp4","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","controls":true,"_view_count":null,"width":"","_view_module_version":"1.5.0","layout":"IPY_MODEL_72c0fd68c4ee4a95bb4d22bd5b98db97","height":"","_model_module":"@jupyter-widgets/controls","loop":true,"autoplay":true}},"72c0fd68c4ee4a95bb4d22bd5b98db97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"xrjZTtw2rMCf"},"source":["# Deep Learning project\n","Intro by Tatiana"]},{"cell_type":"code","metadata":{"id":"QiaLI5xU4EeM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502616698,"user_tz":-60,"elapsed":25652,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"1e17a1fc-ffe9-42f5-93d7-e5da295e562f"},"source":["# Libraries\n","# Colab libraries\n","from google.colab import drive\n","from google.colab import output\n","drive.mount('/content/gdrive')\n","colab_path = \"/content/gdrive/My Drive/Colab Notebooks/\"\n","\n","# Basis libraries\n","import os, re, sys, math, time, scipy, argparse, copy\n","import cv2, matplotlib, json\n","import numpy as np\n","import matplotlib.gridspec as gridspec\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from ipywidgets import Video\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision\n","from torchsummary import summary\n","from collections import OrderedDict\n","from scipy.ndimage.morphology import generate_binary_structure\n","from scipy.ndimage.filters import gaussian_filter, maximum_filter"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V1b25TcW4ik9"},"source":["## Section 0: Download and install repository\n","First, we will download the repository that we copied from the [original repository](https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation) in order to make some changes for educational purposes. Then, we install libraries and some dependences explained in the original repository."]},{"cell_type":"code","metadata":{"id":"dKtbnvkHrBfA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502645182,"user_tz":-60,"elapsed":54124,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"11823039-3d15-4ed3-e499-a9e5dcbf819b"},"source":["# Independence install\n","!sudo apt-get install swig\n","%cd $colab_path\n","if not os.path.isdir(\"RT-multiperson-pose-pytorch\"):\n","  # Repository clone\n","  !git clone https://github.com/Johansmm/RT-multiperson-pose-pytorch.git\n","  %cd \"RT-multiperson-pose-pytorch\"\n","  %cd lib/pafprocess \n","  # Repository compile\n","  !sh make.sh\n","\n","# Libraries install\n","%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n","!python -m pip install -r ./requirements.txt\n","!git submodule init && git submodule update\n","# Weights download\n","if not os.path.isfile(\"./pose_model.pth\"):\n","  !wget https://www.dropbox.com/s/ae071mfm2qoyc8v/pose_model.pth\n","output.clear()\n","print(\"[INFO]: Proyect uploaded successfully\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[INFO]: Proyect uploaded successfully\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OXqO9ha9lQao","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502689610,"user_tz":-60,"elapsed":98543,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"0fe00ace-433f-43ad-ecd9-22fd732b4d47"},"source":["!python demo/picture_demo.py"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Bulding VGG19\n","Done !\n","0.5459940652818991\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MNWcHBWR6K7n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502689611,"user_tz":-60,"elapsed":98536,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"a708148a-dff0-460d-e0c5-53a941a9d32d"},"source":["# Framework libraries\n","%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n","sys.path.append('.')\n","from lib.network.rtpose_vgg import get_model\n","from lib.network import im_transform\n","from lib.utils.common import Human, BodyPart, CocoPart, CocoColors, CocoPairsRender, draw_humans\n","from lib.utils.paf_to_pose import paf_to_pose_cpp\n","from lib.config import cfg, update_config\n","from evaluate.coco_eval import get_outputs, handle_paf_and_heat, run_eval"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/RT-multiperson-pose-pytorch\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"174xVRPR9QN-"},"source":["## Section 2: Replication of results\n","In this section we replicated some resutls. First, we need download the data. For this case, we will use the `sh` compiler provided by [original repository](https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation)"]},{"cell_type":"code","metadata":{"id":"3uBTojMrmtud","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502689612,"user_tz":-60,"elapsed":98527,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"dff5317e-3a30-443b-92f5-2f90e5c4ac00"},"source":["%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n","data_download = False # For download COCO dataset\n","if data_download and not os.path.isdir(\"data/coco\"):\n","  !mkdir data\n","  %cd data\n","  !sh ../lib/datasets/CocoDataDownloader.sh\n","  %cd $colab_path\"/RT-multiperson-pose-pytorch\"\n","  output.clear()\n","  print(\"[INFO]: Coco database downloaded successfully\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/RT-multiperson-pose-pytorch\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MekeFPVJ2gKJ"},"source":["Now, we defined some principal functions and the neuronal network architecture.\n","\n"]},{"cell_type":"code","metadata":{"id":"78deQRcV2mOz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502695280,"user_tz":-60,"elapsed":104187,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"c44e3111-033b-4047-e958-afb5de9d8d41"},"source":["%cd $colab_path\"/RT-multiperson-pose-pytorch\"\n","class Namespace:\n","  def __init__(self, **kwargs):\n","    self.__dict__.update(kwargs)\n","\n","def load_rtpose_model():\n","  args = Namespace(cfg = './experiments/vgg19_368x368_sgd.yaml', weight = 'pose_model.pth', opts = [])\n","  update_config(cfg, args)\n","  model = get_model('vgg19')     \n","  model.load_state_dict(torch.load(args.weight))\n","  model = torch.nn.DataParallel(model).cuda()\n","  model.float()\n","  model.eval()\n","  return model\n","\n","def im_forward(image, model):\n","  with torch.no_grad():\n","    paf, heatmap, im_scale = get_outputs(image, model, 'rtpose')\n","  return paf, heatmap, im_scale\n","\n","def human_forward(image, model):\n","  paf, heatmap, im_scale = im_forward(image, model)\n","  humans = paf_to_pose_cpp(heatmap, paf, cfg)\n","  return draw_humans(image, humans), humans\n","\n","rtpose_model = load_rtpose_model()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/RT-multiperson-pose-pytorch\n","Bulding VGG19\n","Done !\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"byx2nJ0pYI5l"},"source":["In order to display some results, images will be chosen at random to reproduce the paper's results. A grid will be created with some samples."]},{"cell_type":"code","metadata":{"id":"RAFCo3hQXxKr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502695283,"user_tz":-60,"elapsed":104180,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"c7a04b31-aae2-4ace-e156-c339e574c2c9"},"source":["def readFileList(file_directory, ext = 'jpg'):\n","    files_list = []\n","    if os.path.isdir(file_directory): # Return files with 'json' extension\n","        for root_path, _, files_name in os.walk(file_directory):\n","            files_list += [os.path.join(root_path, element) for element in files_name if element.split(\".\")[-1].lower() == ext.lower()]\n","    elif file_directory.split('.')[-1] == ext: files_list = [file_directory] # Return file inside of list\n","    return files_list\n","\n","file_list = readFileList(\"./data/coco/images/test2017\")\n","if len(file_list) > 0:\n","    print(\"[INFO]: Images through RT-multiperson pose 2D:\")\n","    fig = plt.figure(figsize=(20, 15), constrained_layout=False)\n","    gs = fig.add_gridspec(nrows=30, ncols=19, wspace=0.0, hspace=0.0)\n","    fig_axes = {\n","        fig.add_subplot(gs[:12, :6]): {\"id\": \"image1_1\"}, # First column\n","        fig.add_subplot(gs[12:20, :6]): {\"id\": \"image2_1\"},\n","        fig.add_subplot(gs[20:, :7]): {\"id\": \"image3_1\"},\n","        fig.add_subplot(gs[:8, 6:13]): {\"id\": \"image1_2\"}, # Second column\n","        fig.add_subplot(gs[8:20, 6:13]): {\"id\": \"image2_2\"},\n","        fig.add_subplot(gs[20:, 7:13]): {\"id\": \"image3_2\"},\n","        fig.add_subplot(gs[:7, 13:]): {\"id\": \"image7\"}, # Third column\n","        fig.add_subplot(gs[7:16, 13:]): {\"id\": \"image8\"},\n","        fig.add_subplot(gs[16:22, 13:]): {\"id\": \"image9\"},\n","        fig.add_subplot(gs[22:, 13:]): {\"id\": \"image10\"},\n","    }\n","\n","    for ax, prop in fig_axes.items():\n","        human_det = []\n","        while len(human_det) == 0:\n","            image = cv2.imread(np.random.choice(file_list))\n","            image_rt, human_det = human_forward(image, rtpose_model)\n","        ax.imshow(cv2.cvtColor(image_rt, cv2.COLOR_BGR2RGB), aspect = \"auto\")\n","        ax.set_xticklabels([]); ax.set_yticklabels([])\n","        ax.set_xticks([]); ax.set_yticks([]); ax.axis(\"on\")\n","    fig.show()\n","else:\n","    print(\"[INFO]: Not image found. Please check image folder\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[INFO]: Not image found. Please check image folder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E0Ejah7GdXBN","executionInfo":{"status":"ok","timestamp":1607502695284,"user_tz":-60,"elapsed":104179,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["isrun = False\n","try:\n","    if isrun:\n","        run_eval(image_dir= './data/coco/images/val2017', \n","          anno_file = './data/coco/annotations/annotations/person_keypoints_val2017.json', \n","          vis_dir = './data/coco/images/vis_val2017', model=model, preprocess='vgg')\n","except:\n","    pass"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FgimQ8_3u04V"},"source":["The summary of the evaluation statistics are presented below. For the validation set, we can see that the model is recognizing about 13% of the cases correctly, of which we can be sure that about 20% are being well detected.\n","\n","<table>\n","<tbody>\n","  <tr>\n","    <th>Average Precision (AP)</th> <th>IoU=0.50:0.95</th> <th>area = all</th> <th>maxDets = 20</th> <th>0.091</th>\n","  </tr>\n","  <tr>\n","    <th>Average Precision (AP)</th> <th>IoU=0.50</th> <th>area = all</th> <th>maxDets = 20</th> <th>0.223</th>\n","  </tr>\n","  <tr>\n","    <th>Average Precision (AP)</th> <th>IoU=0.75</th> <th>area = all</th> <th>maxDets = 20</th> <th>0.057</th>\n","  </tr>\n","  <tr>\n","    <th>Average Precision (AP)</th> <th>IoU=0.50:0.95</th> <th>area = medium</th> <th>maxDets = 20</th> <th>0.131</th>\n","  </tr>\n","  <tr>\n","    <th>Average Precision (AP)</th> <th>IoU=0.50:0.95</th> <th>area = large</th> <th>maxDets = 20</th> <th>0.091</th>\n","  </tr>\n","  <tr>\n","    <th>Average Recall (AR)</th> <th>IoU=0.50:0.95</th> <th>area = all</th> <th>maxDets = 20</th> <th>0.188</th>\n","  </tr>\n","  <tr>\n","    <th>Average Recall (AR)</th> <th>IoU=0.50</th> <th>area = all</th> <th>maxDets = 20</th> <th>0.350</th>\n","  </tr>\n","  <tr>\n","    <th>Average Recall (AR)</th> <th>IoU=0.75</th> <th>area = all</th> <th>maxDets = 20</th> <th>0.167</th>\n","  </tr>\n","  <tr>\n","    <th>Average Recall (AR)</th> <th>IoU=0.50:0.95</th> <th>area = medium</th> <th>maxDets = 20</th> <th>0.140</th>\n","  </tr>\n","  <tr>\n","    <th>Average Recall (AR)</th> <th>IoU=0.50:0.95</th> <th>area = large</th> <th>maxDets = 20</th> <th>0.255</th>\n","  </tr>\n","</tbody>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"jAApuRJK7JxM"},"source":["## Section 3: Applications\n","Some applications in the field of deep learning have been developed in recent years with themes relating to the detection of the position of people in different scenes. Some of these include the classification of postures, detection of people in position, robots assisted living, character animation, video games industry, medical applications such as postural corrections, and anothers [interesting projects](https://medium.com/beyondminds/an-overview-of-human-pose-estimation-with-deep-learning-d49eb656739b). Below are some articles of interest:\n","\n","1.   [Multi-Person Pose Estimation for Pose Tracking with Enhanced Cascaded Pyramid Network](https://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Yu_Multi-Person_Pose_Estimation_for_Pose_Tracking_with_Enhanced_Cascaded_Pyramid_ECCVW_2018_paper.pdf)\n","2.   [Single-Stage Multi-Person Pose Machines](https://arxiv.org/pdf/1908.09220.pdf)\n","3.   [Rehabilitation Posture Correction Using Deep Neural\n","Network](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7881743)\n","4.   [Pose Trainer: Correcting Exercise Posture using Pose Estimation](https://arxiv.org/abs/2006.11718)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-Ysg5djnUntE"},"source":["In this notebook, we will attack in a particular aplication: The detection of multiple person poses in videos and their prediction in later frames. For this, we will use the [`tv_human_interactions`](https://www.robots.ox.ac.uk/~vgg/data/tv_human_interactions/) database."]},{"cell_type":"markdown","metadata":{"id":"_Wwp9Gc9Bg2Q"},"source":["### Problem context\n","\n","We must understand that for every image in the video, we have that the network predicts an affinity map and a body part map, with sizes  $(46,83,38)$ and $(46,83,19)$, respectively. To predict the pose in future frames of a video we will use this information as an RCNN target, coupling each detection in a single tensor. The idea will be to be able to predict these two maps of a given frame a map of the current state, coupled into a single map set of $(46,83,57)$ size for a single image."]},{"cell_type":"markdown","metadata":{"id":"eYn0nymvc1_E"},"source":["### Download database\n","\n","As mentioned above, the database will be downloaded from [`tv_human_interactions`](https://www.robots.ox.ac.uk/~vgg/data/tv_human_interactions/). A state flag will allow you to switch between downloading and not downloading the database."]},{"cell_type":"code","metadata":{"id":"hR5UNP5Xdc2w","executionInfo":{"status":"ok","timestamp":1607502695284,"user_tz":-60,"elapsed":104177,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["download_tv_human = False\n","if download_tv_human and not os.path.isdir(\"./data/tv_human_interactions_videos\"):\n","    if not os.path.isdir(\"./data\"): os.mkdir(\"./data\")\n","    !wget -P \"./data\" \"https://www.robots.ox.ac.uk/~vgg/data/tv_human_interactions/data/tv_human_interactions_videos.tar.gz\"\n","    !tar -xzvf \"./data/tv_human_interactions_videos.tar.gz\" -C \"./data\"\n","    os.remove(\"./data/tv_human_interactions_videos.tar.gz\")\n","    output.clear()\n","    print(\"[INFO] TV Human Interactions database download succesfully!.\")"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hpcf2siNR6Qi"},"source":["### Architecture implementation in videos\n","Let's start with the implementation of the architecture in a test video. We will make the frame to frame reading, showing the result of the estimation."]},{"cell_type":"code","metadata":{"id":"d9BuVeQxSEab","executionInfo":{"status":"ok","timestamp":1607502695285,"user_tz":-60,"elapsed":104176,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["''' Extract properties from video '''\n","def video_prop_read(video_path, force_mp4 = True):\n","    video = cv2.VideoCapture(video_path) # Read video\n","    w,h = int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    video_fps = video.get(cv2.CAP_PROP_FPS)\n","    codec = [chr((int(video.get(cv2.CAP_PROP_FOURCC)) >> 8 * i) & 0xFF) for i in range(4)]\n","    video_size = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n","    video.release()\n","    if \"mp4\" in os.path.splitext(video_path)[-1].lower() or force_mp4: codec = ['m', 'p', '4', 'v']\n","    if video_size <= 0: video_size = np.inf\n","    if video_fps <= 0 or video_fps == np.inf: video_fps = 25 # Default value\n","    return w, h, video_fps, codec, video_size\n","\n","''' Show embed video'''\n","def show_video(video_path):\n","    filename, ext = os.path.splitext(video_path)\n","    if os.path.isfile(video_path):\n","        if \"mp4\" not in ext.lower():\n","            filename += \".mp4\"\n","            !sudo ffmpeg -t 5 -i \"$video_path\" \"$filename\" # Convert any ext to mp4\n","            output.clear()\n","            video_path = filename\n","        video = Video.from_file(video_path)\n","    else:\n","        print(\"[ERROR] Video file not found. Please check path.\")\n","        video = None\n","    return video\n","\n","''' Draw humans in video '''\n","def video_forward(video_in, fps = None, video_out_path = None, force_mp4 = True,\n","                  total_frames = None, skip_frames = None, resize = None, \n","                  background = True, print_im = False):\n","    # Read video properties\n","    video_w, video_h, video_fps, video_codec, video_size = video_prop_read(video_in, force_mp4)\n","    video = cv2.VideoCapture(video_in)\n","\n","    # Video object to save and video_in read\n","    if fps is not None and fps < video_fps: video_fps = fps\n","    if video_out_path is not None:\n","        video_out_path, ext = os.path.splitext(video_out_path)\n","        if force_mp4: video_out_path += \".mp4\"\n","        elif len(ext) == 0: video_out_path += os.path.splitext(video_in)[-1]\n","        else: video_out_path += ext\n","        if resize is not None: video_w, video_h = resize\n","        video_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*video_codec), \n","                                    video_fps, (video_w, video_h))\n","        print(\"[INFO]: Video will be saved in\", video_out_path)\n","\n","    fcount = 0; tic = time.time(); total_paf = []; total_heat = []; sizes = []; rcount = 0\n","    while video.isOpened():\n","        ret, frame = video.read(); fcount += 1\n","        if fps is not None and fcount % (fps//video_fps) != 0: continue # Skip frames\n","        rcount += 1\n","        if skip_frames is not None and rcount <= skip_frames : continue # Skip frames\n","        if (cv2.waitKey(1) & 0xFF == ord('q')) or not ret: break # End of video\n","\n","        # Detection process\n","        paf, heatmap, im_scale = im_forward(frame, rtpose_model) # CNN maps\n","        total_paf += [paf]; total_heat += [heatmap]; sizes += [im_scale] # Concat detections\n","\n","        # Save pose-detection in video_out\n","        if video_out_path is not None or print_im:\n","            humans = paf_to_pose_cpp(heatmap, paf, cfg)\n","            if not background: frame = np.zeros(frame.shape, dtype = \"uint8\")\n","            frame_out = draw_humans(frame, humans)\n","            if resize is not None: frame_out = cv2.resize(frame_out, resize)\n","            if video_out_path is not None: video_out.write(frame_out)\n","        \n","        # if isprogrammer: cv2.imshow(\"output.mp4\", frame)\n","        if fcount % 30 == 0:\n","            print(\"[INFO]: {} of {} frames processed.\".format(fcount, video_size))\n","            if print_im: \n","                plt.imshow(cv2.cvtColor(frame_out, cv2.COLOR_BGR2RGB))\n","                plt.axis(\"off\"); plt.show()\n","        \n","        if total_frames is not None and rcount >= total_frames: break # End\n","        \n","    video.release()\n","    if video_out_path is not None: \n","        video_out.release()\n","        if \"mp4\" in os.path.splitext(video_out_path)[-1]:\n","            video_out_path_compress = video_out_path.replace(\".mp4\",\"_out.mp4\")\n","            !sudo ffmpeg -t 5 -i \"$video_out_path\" \"$video_out_path_compress\" # Compress\n","            !mv \"$video_out_path_compress\" \"$video_out_path\"\n","            !rm \"$video_out_path_compress\"\n","            output.clear()\n","        print(\"[INFO]: Video saved successfully\")\n","    print(\"[INFO]: Total time spend in procedure:\", time.time() - tic, \"s\")\n","    if len(total_paf) == 0: return None, None, None\n","    else: return np.stack(total_paf, axis = 0), np.stack(total_heat, axis = 0), sizes"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwoU7KeEaYr5","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1607502715456,"user_tz":-60,"elapsed":124338,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"89a50803-06e1-4a5a-cef0-5908a9c818e7"},"source":["video_path_proof = \"./data/Videos_Deep_MiosHAHA/Entrenamiento/Original1_Train.mp4\"\n","demo_pred = video_forward(video_path_proof, video_out_path = \"./demo/video_demo\", \n","                          resize = (720,480), fps = 150, background = True, print_im = True)\n","print(demo_pred[0].shape, demo_pred[1].shape)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[INFO]: Video saved successfully\n","[INFO]: Total time spend in procedure: 15.196351289749146 s\n","(47, 46, 82, 38) (47, 46, 82, 19)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Rg8J-ACbpon","colab":{"base_uri":"https://localhost:8080/","height":505,"referenced_widgets":["59a55a06af4c4105802e8ee7b82f1e09","72c0fd68c4ee4a95bb4d22bd5b98db97"]},"executionInfo":{"status":"ok","timestamp":1607502715458,"user_tz":-60,"elapsed":124330,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"f25ae5ce-9fe6-4dee-af25-892d746deff3"},"source":["show_video(\"./demo/video_demo.mp4\")"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59a55a06af4c4105802e8ee7b82f1e09","version_minor":0,"version_major":2},"text/plain":["Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\x07\\xc1\\xb5mdat\\x0…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"C8_20lTfccOm"},"source":["### Pose-database creation\n","After we have tested the network in a simple video, we will split the video list files into test, train and validation sets.\n","\n","In addition, we will perform a mini-batch training, where each batche will be represented by each video. Therefore, we will define a function that will allow us to process each video and organize it in tensors, so that it organizes the information for the input/output training process. As the input is the composition of the prediction in $N$ previous states to predict the $N+1$ state (output), the dimenssions of the input tensor will be of $(x,N,46,83,57)$ and $(x,46,83,57)$ for the output, with $x$ the total of images in the video. If we desired $N=1$, $(x,46,83,57)$ will be the dimension of the entry tensor."]},{"cell_type":"code","metadata":{"id":"BDO1QRgScbkV","executionInfo":{"status":"ok","timestamp":1607502715460,"user_tz":-60,"elapsed":124329,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["# Train, test and valid video lists creation\n","random_state = 42\n","# video_list = readFileList(\"./data/tv_human_interactions_videos/\", ext = 'avi')\n","# videoloaders = {x:y for x,y in zip([\"train\",\"test\"], train_test_split(video_list, test_size = 0.3, random_state = random_state))}\n","# videoloaders.update({x:y for x,y in zip([\"valid\",\"test\"], train_test_split(videoloaders[\"test\"], test_size = 0.5, random_state = random_state))})\n","# video_set_sizes = {x: len(videoloaders[x]) for x in ['train', 'valid', 'test']}\n","# print(video_set_sizes)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgtVyOhws1mJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607502715855,"user_tz":-60,"elapsed":124710,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}},"outputId":"a72cd5af-180c-4456-baff-f15c8fb54d5c"},"source":["np.random.seed(random_state)\n","videoloaders = {x:readFileList(\"./data/Videos_Deep_MiosHAHA/\" + y, ext = \"mp4\") for x,y in zip([\"train\",\"valid\",\"test\"],[\"Entrenamiento\",\"Validacion\",\"Test\"])}\n","video_set_sizes = {x: len(videoloaders[x]) for x in ['train', 'valid', 'test']}\n","print(video_set_sizes)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["{'train': 8, 'valid': 8, 'test': 8}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6t2KeflHEJ9I","executionInfo":{"status":"ok","timestamp":1607502715857,"user_tz":-60,"elapsed":124710,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["# Load (predict) video and split it in in/out tensor\n","def video_batch(video_path, n_past_step = 12, n_fut_step = 12, \n","                batch_size = None, skip_batch = None, **kwargs): # (b,t,c,h,w)\n","    total_frames = batch_size; skip_frames = skip_batch\n","    if skip_frames is not None: skip_frames *= n_past_step + n_fut_step\n","    if batch_size is not None: \n","        total_frames *= n_past_step + n_fut_step\n","        if skip_frames is not None: total_frames += skip_frames\n","        \n","    tpaf, theat, _ = video_forward(video_path, # Video forward in RT-model (frames,h,w,c)\n","            total_frames = total_frames, skip_frames = skip_frames, **kwargs)\n","    if tpaf is None or theat is None: return None, None\n","    paf_batch, heat_batch = [], []\n","    for t in range(len(tpaf)//(n_past_step + n_fut_step)): # Batches of (B,n_steps,H,W,C)\n","        paf_batch.append(tpaf[t*(n_past_step + n_fut_step):(t+1)*(n_past_step + n_fut_step)])\n","        heat_batch.append(theat[t*(n_past_step + n_fut_step):(t+1)*(n_past_step + n_fut_step)])\n","    if len(heat_batch) == 0 or len(paf_batch) == 0: return None, None\n","    paf_batch = torch.from_numpy(np.stack(paf_batch, axis = 0)).float()\n","    heat_batch = torch.from_numpy(np.stack(heat_batch, axis = 0)).float()\n","    return paf_batch.permute(0,1,4,2,3), heat_batch.permute(0,1,4,2,3) # Tensors organize to (B,past+future,C,H,W)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IFqXrABMBmT"},"source":["### RCNN architecture definition"]},{"cell_type":"code","metadata":{"id":"LI692SOeSJfN","executionInfo":{"status":"ok","timestamp":1607502715858,"user_tz":-60,"elapsed":124709,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["''' Defined a single convLSTM module '''\n","class ConvLSTMCell(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n","        \"\"\"\n","        Initialize ConvLSTM cell.\n","\n","        Parameters\n","        ----------\n","        input_dim: int # Number of channels of input tensor.\n","        hidden_dim: int # Number of channels of hidden state.\n","        kernel_size: (int, int) # Size of the convolutional kernel.\n","        bias: bool # Whether or not to add the bias.\n","        \"\"\"\n","\n","        super(ConvLSTMCell, self).__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.kernel_size = kernel_size\n","        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n","        self.bias = bias\n","\n","        self.conv = nn.Conv2d(in_channels = self.input_dim + self.hidden_dim,\n","                              out_channels = 4 * self.hidden_dim,\n","                              kernel_size = self.kernel_size,\n","                              padding = self.padding, bias = self.bias)\n","\n","    def forward(self, input_tensor, cur_state):\n","        h_cur, c_cur = cur_state\n","\n","        # concatenate along channel axis\n","        combined = torch.cat([input_tensor, h_cur], dim = 1) # (B,c,h,w)\n","\n","        combined_conv = self.conv(combined)\n","        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim = 1)\n","        i = torch.sigmoid(cc_i) # (B, hidden, h, w)\n","        f = torch.sigmoid(cc_f)\n","        o = torch.sigmoid(cc_o)\n","        g = torch.tanh(cc_g)\n","\n","        c_next = f * c_cur + i * g\n","        h_next = o * torch.tanh(c_next)\n","\n","        return h_next, c_next\n","\n","    def init_hidden(self, batch_size, image_size):\n","        height, width = image_size\n","        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n","                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkMZRCoESYfm","executionInfo":{"status":"ok","timestamp":1607502715859,"user_tz":-60,"elapsed":124709,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["class EncoderDecoderConvLSTM(nn.Module):\n","    def __init__(self, nf, in_chan):\n","        super(EncoderDecoderConvLSTM, self).__init__()\n","\n","        \"\"\" ARCHITECTURE \n","\n","        # Encoder (ConvLSTM)\n","        # Encoder Vector (final hidden state of encoder)\n","        # Decoder (ConvLSTM) - takes Encoder Vector as input\n","        # Decoder (3D CNN) - produces regression predictions for our model\n","\n","        \"\"\"\n","        # PAF predictions\n","        self.encoder_1_2_convlstm = ConvLSTMCell(input_dim=in_chan[0], hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","        self.encoder_1_convlstm = ConvLSTMCell(input_dim=nf, hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","        \n","        self.decoder_1_2_convlstm = ConvLSTMCell(input_dim=nf, hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","        self.decoder_1_convlstm = ConvLSTMCell(input_dim=nf, hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","        \n","\n","        self.decoder_1_CNN = nn.Conv3d(in_channels=nf, out_channels=in_chan[0], kernel_size=(1, 3, 3), padding=(0, 1, 1))\n","\n","        # Heatmap predictions\n","        self.encoder_2_2_convlstm = ConvLSTMCell(input_dim=in_chan[1], hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","        self.encoder_2_convlstm = ConvLSTMCell(input_dim=nf, hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","        \n","\n","        self.decoder_2_convlstm = ConvLSTMCell(input_dim=nf, hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","        self.decoder_2_2_convlstm = ConvLSTMCell(input_dim=nf, hidden_dim=nf, kernel_size=(3, 3), bias=True)\n","\n","        self.decoder_2_CNN = nn.Conv3d(in_channels=nf, out_channels=in_chan[1], kernel_size=(1, 3, 3), padding=(0, 1, 1))\n","\n","    def autoencoder(self, x, seq_len, future_step, h_t5, c_t5,h_t, c_t,h_t6, c_t6, h_t2, c_t2,h_t7, c_t7, h_t3, c_t3,h_t8, c_t8, h_t4, c_t4):\n","        # encoder\n","        for t in range(seq_len):\n","            \n","            h_t5, c_t5 = self.encoder_1_2_convlstm(input_tensor = x[0][:, t, :, :, :], cur_state=[h_t5, c_t5])\n","            h_t, c_t = self.encoder_1_convlstm(input_tensor = h_t5, cur_state=[h_t, c_t])\n","\n","            h_t6, c_t6 = self.encoder_2_2_convlstm(input_tensor = x[1][:, t, :, :, :], cur_state=[h_t6, c_t6])\n","            h_t2, c_t2 = self.encoder_2_convlstm(input_tensor = h_t6, cur_state=[h_t2, c_t2])\n","        \n","        encoder_vector = [h_t, h_t2] # (B, Hidden, H, W)\n","\n","        # decoder\n","        paf_outputs, heat_outputs = [], []\n","\n","        for t in range(future_step):\n","\n","            h_t7, c_t7 = self.decoder_1_2_convlstm(input_tensor=encoder_vector[0], cur_state=[h_t7, c_t7])\n","            h_t3, c_t3 = self.decoder_1_convlstm(input_tensor=h_t7, cur_state=[h_t3, c_t3])\n","\n","            h_t8, c_t8 = self.decoder_2_2_convlstm(input_tensor=encoder_vector[1], cur_state=[h_t8, c_t8])\n","            h_t4, c_t4 = self.decoder_2_convlstm(input_tensor=h_t8, cur_state=[h_t4, c_t4])\n","\n","            encoder_vector = [h_t3, h_t4] # (B,hidden,H,W)\n","            paf_outputs += [h_t3]; heat_outputs += [h_t4] # predictions\n","\n","        # PAF prediction\n","        paf_outputs = torch.stack(paf_outputs, dim = 1) # (B,future_step,hidden,H,W)\n","        paf_outputs = paf_outputs.permute(0, 2, 1, 3, 4) # (B,hidden,future_step,H,W)\n","        paf_outputs = self.decoder_1_CNN(paf_outputs) # (B,C,future_step,H,W)\n","        paf_outputs = torch.nn.Tanh()(paf_outputs)\n","        paf_outputs = paf_outputs.permute(0, 2, 1, 3, 4) # (B,future_step,C,H,W)\n","\n","        # Heat predictions\n","        heat_outputs = torch.stack(heat_outputs, dim = 1) # (B,future_step,hidden,H,W)\n","        heat_outputs = heat_outputs.permute(0, 2, 1, 3, 4) # (B,hidden,future_step,H,W)\n","        heat_outputs = self.decoder_2_CNN(heat_outputs) # (B,C,future_step,H,W)\n","        heat_outputs = torch.nn.Tanh()(heat_outputs)\n","        heat_outputs = heat_outputs.permute(0, 2, 1, 3, 4) # (B,future_step,C,H,W)\n","        return paf_outputs, heat_outputs\n","    \n","    def forward(self, x, n_step_fut, hidden_state = None):\n","\n","        \"\"\"\n","        Parameters\n","        ----------\n","        input_tensor:\n","            List with two 5-D Tensor of shape (b, t, c, h, w) # batch, time, channel, height, width\n","        \"\"\"\n","\n","        # find size of different input dimensions\n","        b, seq_len, _, h, w = x[0].size()\n","\n","        # initialize hidden states\n","        if hidden_state is None:\n","            h_t5, c_t5 = self.encoder_1_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","            h_t, c_t = self.encoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","            h_t6, c_t6 = self.encoder_2_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","            h_t2, c_t2 = self.encoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","            h_t7, c_t7 = self.decoder_1_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","            h_t3, c_t3 = self.decoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","            h_t8, c_t8 = self.decoder_2_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","            h_t4, c_t4 = self.decoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n","        else:\n","            (h_t5, c_t5),(h_t, c_t),(h_t6, c_t6), (h_t2, c_t2),(h_t7, c_t7), (h_t3, c_t3),(h_t8, c_t8), (h_t4, c_t4) = hidden_state\n","\n","        # autoencoder forward\n","        outputs = self.autoencoder(x, seq_len, n_step_fut, h_t5, c_t5,h_t, c_t,h_t6, c_t6, h_t2, c_t2,h_t7, c_t7, h_t3, c_t3,h_t8, c_t8, h_t4, c_t4)\n","\n","        return outputs"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fEpx0dAMTUfh"},"source":["### Training model definition\n","\n"]},{"cell_type":"code","metadata":{"id":"M4nkUuEkTTvG","executionInfo":{"status":"ok","timestamp":1607502715859,"user_tz":-60,"elapsed":124708,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["def train_step(model, criterion, optimizer = None, phase = 'valid', **kwargs):\n","    if phase == 'train': model.train()  # Set model to training mode\n","    else: model.eval() # Set model to evaluate mode\n","\n","    skip_batch, losses, batch_count = 0, 0.0, 0\n","    while True:\n","        paf_batch, heat_batch = video_batch(skip_batch = skip_batch, **kwargs) # Batch of (B,frames,C,H,W)\n","        if paf_batch is None or heat_batch is None: break # Invalid video read.\n","        batch_count += 1\n","\n","        # Batch I/O split\n","        x_paf = paf_batch[:, :kwargs[\"n_past_step\"]].cuda() # Batch of (B,n_steps,C,H,W)\n","        y_paf = paf_batch[:, kwargs[\"n_past_step\"]:].cuda() # Batch of (B,future_step,C,H,W)\n","        x_heat = heat_batch[:, :kwargs[\"n_past_step\"]].cuda() # Batch of (B,n_steps,C,H,W)\n","        y_heat = heat_batch[:, kwargs[\"n_past_step\"]:].cuda() # Batch of (B,future_step,C,H,W)\n","\n","        # forward\n","        with torch.set_grad_enabled(phase == 'train'): # track history if only in train\n","            y_hat1, y_hat2 = model([x_paf, x_heat], n_step_fut = kwargs[\"n_fut_step\"])\n","            loss = criterion(y_hat1, y_paf) + criterion(y_hat2, y_heat)\n","            if phase == 'train': # backward + optimize only if in training phase\n","                optimizer.zero_grad(); loss.backward(); optimizer.step()\n","\n","        losses += loss.item() * x_paf.size(0) # Total images\n","        \n","        if kwargs[\"batch_size\"] is not None: skip_batch += kwargs[\"batch_size\"]\n","        else: break # Invalid video read.\n","    if batch_count == 0: return None\n","    else: return losses/batch_count\n","\n","def load_stats(model, stat_name, model_name):\n","    if stat_name is not None and os.path.isfile(stat_name):\n","        with open(stat_name, \"r\") as f: stats = json.load(f) # Recovery stats\n","        if model_name is not None: stats[\"model_name\"] = model_name\n","    else:\n","        stats = {\"losses\": {\"train\": [], \"valid\": []}, \"cur_epoch\":0, # Variable to save all\n","                \"best_epoch\": 0, \"best_loss\": np.inf, \"time_process\": 0,\n","                 \"model_name\": model_name}\n","    try:\n","        model.load_state_dict(torch.load(stats[\"model_name\"]))\n","        model.cuda()\n","    except:\n","        pass\n","    return model, stats\n","\n","def training(EDconvLST_model, criterion, optimizer, scheduler = None, num_epochs = 25, \n","             model_name = None, early_max = None, n_steps_past = 10, future_step = 10, \n","             stat_name = None, batch_size = None):\n","    \n","    since = time.time(); count_max = 0; tic = since\n","\n","    # Model initialization\n","    EDconvLST_model, stats = load_stats(EDconvLST_model, stat_name, model_name)\n","    t0 = stats[\"time_process\"]\n","    if stats[\"cur_epoch\"] >= num_epochs: \n","        print(\"[INFO] Model already was training. Return (if exist) the train model\")\n","        if stats[\"model_name\"] is None: EDconvLST_model = None\n","        return EDconvLST_model, stats\n","    \n","    # Train process\n","    for epoch in range(1, num_epochs+1):\n","        # torch.cuda.empty_cache()\n","        if epoch <= stats[\"cur_epoch\"]: continue # Skip epochs\n","        isprint = num_epochs <= 100 or (epoch-1) % (num_epochs // 10) == 0 or epoch == num_epochs\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'valid']:\n","            # Iterate over data.\n","            running_loss = 0.0\n","            np.random.shuffle(videoloaders[phase])\n","            for i,video_path in enumerate(videoloaders[phase]): # Start for\n","                if isprint: print(\"[INFO] {}: Reading video {}/{}\".format(phase, i, video_set_sizes[phase]))\n","                \n","                loss = train_step(EDconvLST_model, criterion, optimizer = optimizer, phase = phase, \n","                                  video_path = video_path, n_past_step = n_steps_past, n_fut_step = future_step, \n","                                  batch_size = batch_size, resize = (720,480), fps = 150)\n","                \n","                if isprint: \n","                    output.clear()\n","                    print('\\nEpoch {}/{}\\n{}'.format(epoch, num_epochs, '-'*15))\n","                    if len(stats[\"losses\"][\"train\"]) > 0: train_loss = stats[\"losses\"][\"train\"][-1]\n","                    else: train_loss = np.inf\n","                    if loss is not None:\n","                        print('[INFO] {}: Current loss = {:.6f}, last train loss = {:.6f}, best valid loss = {:.6f}'.\\\n","                          format(phase, loss, train_loss, stats[\"best_loss\"]))\n","                    else:\n","                        print('[INFO] {}: Last train loss = {:.6f}, best valid loss = {:.6f}'.\\\n","                          format(phase, train_loss, stats[\"best_loss\"]))\n","            \n","                if loss is not None: running_loss += loss\n","            if isprint: output.clear() # Errase print info\n","            if phase == 'train' and scheduler is not None: scheduler.step()\n","            stats[\"losses\"][phase].append(running_loss/video_set_sizes[phase])\n","        \n","        time_elapsed = time.time() - tic\n","        if isprint: # Print somethings for some epoch\n","            print('train Loss: {:.6f} \\tvalid Loss: {:.6f}. Spend time:{:.0f}m {:.0f}s'\\\n","                .format(stats[\"losses\"][\"train\"][-1], stats[\"losses\"][\"valid\"][-1], time_elapsed // 60, time_elapsed % 60))\n","            tic = time.time() # For next iteration\n","\n","        # deep save model\n","        if stats[\"losses\"][\"valid\"][-1] < stats[\"best_loss\"]:\n","            if isprint: \n","                print('Valid loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(stats[\"best_loss\"], stats[\"losses\"][\"valid\"][-1]))\n","            stats[\"best_epoch\"] = epoch\n","            stats[\"best_loss\"] = stats[\"losses\"][\"valid\"][-1]\n","            best_model_wts = copy.deepcopy(EDconvLST_model.state_dict())\n","            if model_name is not None: torch.save(best_model_wts, model_name)\n","            count_max = 0\n","        else: \n","            count_max += 1 \n","            if early_max is not None and count_max >= early_max: break # Early finish training\n","\n","        stats[\"time_process\"] = time.time() - since + t0\n","        stats[\"cur_epoch\"] = epoch\n","        if stat_name is not None: \n","            with open(stat_name, \"w\") as f: json.dump(stats, f)\n","\n","    print('\\n{}\\nTraining complete ({}/{} epochs) in {:.0f}m {:.0f}s'\\\n","          .format('-'*25, epoch, num_epochs, stats[\"time_process\"] // 60, stats[\"time_process\"] % 60))\n","    print('Best metric (loss): {:4f}'.format(stats[\"best_loss\"]))\n","\n","    # load best model weights\n","    EDconvLST_model.load_state_dict(best_model_wts)\n","    EDconvLST_model.cuda()\n","    return EDconvLST_model, stats"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28xlkBcmbEWQ"},"source":["### User parameters"]},{"cell_type":"code","metadata":{"id":"ToOGoqWG_Oau","executionInfo":{"status":"ok","timestamp":1607502715860,"user_tz":-60,"elapsed":124701,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["# User parameters\n","n_steps_past = 15\n","n_steps_fut = 1\n","num_epochs = 120"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"eG-HettwbD1S","executionInfo":{"status":"ok","timestamp":1607502715861,"user_tz":-60,"elapsed":124701,"user":{"displayName":"tatiana moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcb6UqDRSLB3ZZ5QeBSpZfcM7hssUIYSIbQsHh=s64","userId":"02108020887084399148"}}},"source":["EDCLSTM_model = EncoderDecoderConvLSTM(nf = 90, in_chan = [38,19])\n","EDCLSTM_model.cuda()\n","criterion = nn.MSELoss(reduction = \"sum\").cuda()\n","# optimizer = optim.SGD(EDCLSTM_model.parameters(), lr = 1e-2 ,momentum=0.9)\n","optimizer = optim.Adam(EDCLSTM_model.parameters(), lr = 1e-2, betas=(0.9, 0.98))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"gZfaZkBhcl08","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4598f11f-4e22-4fac-895b-1ed4d2cf5657"},"source":["model_file = \"EDCLSTM_exp_Adam_LSTM_2_2.pt\"\n","statistics_file = \"EDCLSTM_exp_Adam_LSTM_2_2.json\"\n","EDCLSTM_model, EDCLSTM_stats = training(EDCLSTM_model, criterion, optimizer, batch_size = 7,\n","             num_epochs = num_epochs, early_max = None, n_steps_past = n_steps_past, \n","             future_step = n_steps_fut, stat_name = statistics_file, model_name = model_file)\n","# EDCLSTM_model, EDCLSTM_stats = load_stats(EDCLSTM_model, statistics_file, model_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train Loss: 3284.861499 \tvalid Loss: 216.960351. Spend time:83m 11s\n","[INFO]: 30 of 990 frames processed.\n","[INFO]: 60 of 990 frames processed.\n","[INFO]: 90 of 990 frames processed.\n","[INFO]: 120 of 990 frames processed.\n","[INFO]: 150 of 990 frames processed.\n","[INFO]: 180 of 990 frames processed.\n","[INFO]: 210 of 990 frames processed.\n","[INFO]: 240 of 990 frames processed.\n","[INFO]: 270 of 990 frames processed.\n","[INFO]: 300 of 990 frames processed.\n","[INFO]: 330 of 990 frames processed.\n","[INFO]: 360 of 990 frames processed.\n","[INFO]: 390 of 990 frames processed.\n","[INFO]: 420 of 990 frames processed.\n","[INFO]: 450 of 990 frames processed.\n","[INFO]: 480 of 990 frames processed.\n","[INFO]: 510 of 990 frames processed.\n","[INFO]: 540 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 26.063847541809082 s\n","[INFO]: 570 of 990 frames processed.\n","[INFO]: 600 of 990 frames processed.\n","[INFO]: 630 of 990 frames processed.\n","[INFO]: 660 of 990 frames processed.\n","[INFO]: 690 of 990 frames processed.\n","[INFO]: 720 of 990 frames processed.\n","[INFO]: 750 of 990 frames processed.\n","[INFO]: 780 of 990 frames processed.\n","[INFO]: 810 of 990 frames processed.\n","[INFO]: 840 of 990 frames processed.\n","[INFO]: 870 of 990 frames processed.\n","[INFO]: 900 of 990 frames processed.\n","[INFO]: 930 of 990 frames processed.\n","[INFO]: 960 of 990 frames processed.\n","[INFO]: 990 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 24.859923601150513 s\n","[INFO]: Total time spend in procedure: 8.406476974487305 s\n","[INFO]: 30 of 240 frames processed.\n","[INFO]: 60 of 240 frames processed.\n","[INFO]: 90 of 240 frames processed.\n","[INFO]: 120 of 240 frames processed.\n","[INFO]: 150 of 240 frames processed.\n","[INFO]: 180 of 240 frames processed.\n","[INFO]: 210 of 240 frames processed.\n","[INFO]: 240 of 240 frames processed.\n","[INFO]: Total time spend in procedure: 11.3583824634552 s\n","[INFO]: Total time spend in procedure: 2.3616909980773926 s\n","[INFO]: 30 of 900 frames processed.\n","[INFO]: 60 of 900 frames processed.\n","[INFO]: 90 of 900 frames processed.\n","[INFO]: 120 of 900 frames processed.\n","[INFO]: 150 of 900 frames processed.\n","[INFO]: 180 of 900 frames processed.\n","[INFO]: 210 of 900 frames processed.\n","[INFO]: 240 of 900 frames processed.\n","[INFO]: 270 of 900 frames processed.\n","[INFO]: 300 of 900 frames processed.\n","[INFO]: 330 of 900 frames processed.\n","[INFO]: 360 of 900 frames processed.\n","[INFO]: 390 of 900 frames processed.\n","[INFO]: 420 of 900 frames processed.\n","[INFO]: 450 of 900 frames processed.\n","[INFO]: 480 of 900 frames processed.\n","[INFO]: 510 of 900 frames processed.\n","[INFO]: 540 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 26.164506435394287 s\n","[INFO]: 570 of 900 frames processed.\n","[INFO]: 600 of 900 frames processed.\n","[INFO]: 630 of 900 frames processed.\n","[INFO]: 660 of 900 frames processed.\n","[INFO]: 690 of 900 frames processed.\n","[INFO]: 720 of 900 frames processed.\n","[INFO]: 750 of 900 frames processed.\n","[INFO]: 780 of 900 frames processed.\n","[INFO]: 810 of 900 frames processed.\n","[INFO]: 840 of 900 frames processed.\n","[INFO]: 870 of 900 frames processed.\n","[INFO]: 900 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 20.491236209869385 s\n","[INFO]: Total time spend in procedure: 7.610617637634277 s\n","[INFO]: 30 of 1200 frames processed.\n","[INFO]: 60 of 1200 frames processed.\n","[INFO]: 90 of 1200 frames processed.\n","[INFO]: 120 of 1200 frames processed.\n","[INFO]: 150 of 1200 frames processed.\n","[INFO]: 180 of 1200 frames processed.\n","[INFO]: 210 of 1200 frames processed.\n","[INFO]: 240 of 1200 frames processed.\n","[INFO]: 270 of 1200 frames processed.\n","[INFO]: 300 of 1200 frames processed.\n","[INFO]: 330 of 1200 frames processed.\n","[INFO]: 360 of 1200 frames processed.\n","[INFO]: 390 of 1200 frames processed.\n","[INFO]: 420 of 1200 frames processed.\n","[INFO]: 450 of 1200 frames processed.\n","[INFO]: 480 of 1200 frames processed.\n","[INFO]: 510 of 1200 frames processed.\n","[INFO]: 540 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 25.968634843826294 s\n","[INFO]: 570 of 1200 frames processed.\n","[INFO]: 600 of 1200 frames processed.\n","[INFO]: 630 of 1200 frames processed.\n","[INFO]: 660 of 1200 frames processed.\n","[INFO]: 690 of 1200 frames processed.\n","[INFO]: 720 of 1200 frames processed.\n","[INFO]: 750 of 1200 frames processed.\n","[INFO]: 780 of 1200 frames processed.\n","[INFO]: 810 of 1200 frames processed.\n","[INFO]: 840 of 1200 frames processed.\n","[INFO]: 870 of 1200 frames processed.\n","[INFO]: 900 of 1200 frames processed.\n","[INFO]: 930 of 1200 frames processed.\n","[INFO]: 960 of 1200 frames processed.\n","[INFO]: 990 of 1200 frames processed.\n","[INFO]: 1020 of 1200 frames processed.\n","[INFO]: 1050 of 1200 frames processed.\n","[INFO]: 1080 of 1200 frames processed.\n","[INFO]: 1110 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 30.414749145507812 s\n","[INFO]: 1140 of 1200 frames processed.\n","[INFO]: 1170 of 1200 frames processed.\n","[INFO]: 1200 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 12.727949142456055 s\n","[INFO]: Total time spend in procedure: 9.840757369995117 s\n","[INFO]: 30 of 780 frames processed.\n","[INFO]: 60 of 780 frames processed.\n","[INFO]: 90 of 780 frames processed.\n","[INFO]: 120 of 780 frames processed.\n","[INFO]: 150 of 780 frames processed.\n","[INFO]: 180 of 780 frames processed.\n","[INFO]: 210 of 780 frames processed.\n","[INFO]: 240 of 780 frames processed.\n","[INFO]: 270 of 780 frames processed.\n","[INFO]: 300 of 780 frames processed.\n","[INFO]: 330 of 780 frames processed.\n","[INFO]: 360 of 780 frames processed.\n","[INFO]: 390 of 780 frames processed.\n","[INFO]: 420 of 780 frames processed.\n","[INFO]: 450 of 780 frames processed.\n","[INFO]: 480 of 780 frames processed.\n","[INFO]: 510 of 780 frames processed.\n","[INFO]: 540 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 25.894423961639404 s\n","[INFO]: 570 of 780 frames processed.\n","[INFO]: 600 of 780 frames processed.\n","[INFO]: 630 of 780 frames processed.\n","[INFO]: 660 of 780 frames processed.\n","[INFO]: 690 of 780 frames processed.\n","[INFO]: 720 of 780 frames processed.\n","[INFO]: 750 of 780 frames processed.\n","[INFO]: 780 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 14.924250364303589 s\n","[INFO]: Total time spend in procedure: 6.6179680824279785 s\n","[INFO]: 30 of 600 frames processed.\n","[INFO]: 60 of 600 frames processed.\n","[INFO]: 90 of 600 frames processed.\n","[INFO]: 120 of 600 frames processed.\n","[INFO]: 150 of 600 frames processed.\n","[INFO]: 180 of 600 frames processed.\n","[INFO]: 210 of 600 frames processed.\n","[INFO]: 240 of 600 frames processed.\n","[INFO]: 270 of 600 frames processed.\n","[INFO]: 300 of 600 frames processed.\n","[INFO]: 330 of 600 frames processed.\n","[INFO]: 360 of 600 frames processed.\n","[INFO]: 390 of 600 frames processed.\n","[INFO]: 420 of 600 frames processed.\n","[INFO]: 450 of 600 frames processed.\n","[INFO]: 480 of 600 frames processed.\n","[INFO]: 510 of 600 frames processed.\n","[INFO]: 540 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 25.95913815498352 s\n","[INFO]: 570 of 600 frames processed.\n","[INFO]: 600 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 6.506073951721191 s\n","[INFO]: 30 of 750 frames processed.\n","[INFO]: 60 of 750 frames processed.\n","[INFO]: 90 of 750 frames processed.\n","[INFO]: 120 of 750 frames processed.\n","[INFO]: 150 of 750 frames processed.\n","[INFO]: 180 of 750 frames processed.\n","[INFO]: 210 of 750 frames processed.\n","[INFO]: 240 of 750 frames processed.\n","[INFO]: 270 of 750 frames processed.\n","[INFO]: 300 of 750 frames processed.\n","[INFO]: 330 of 750 frames processed.\n","[INFO]: 360 of 750 frames processed.\n","[INFO]: 390 of 750 frames processed.\n","[INFO]: 420 of 750 frames processed.\n","[INFO]: 450 of 750 frames processed.\n","[INFO]: 480 of 750 frames processed.\n","[INFO]: 510 of 750 frames processed.\n","[INFO]: 540 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 25.81562352180481 s\n","[INFO]: 570 of 750 frames processed.\n","[INFO]: 600 of 750 frames processed.\n","[INFO]: 630 of 750 frames processed.\n","[INFO]: 660 of 750 frames processed.\n","[INFO]: 690 of 750 frames processed.\n","[INFO]: 720 of 750 frames processed.\n","[INFO]: 750 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 13.447708129882812 s\n","[INFO]: Total time spend in procedure: 6.264820337295532 s\n","[INFO]: 30 of 236 frames processed.\n","[INFO]: 60 of 236 frames processed.\n","[INFO]: 90 of 236 frames processed.\n","[INFO]: 120 of 236 frames processed.\n","[INFO]: 150 of 236 frames processed.\n","[INFO]: 180 of 236 frames processed.\n","[INFO]: 210 of 236 frames processed.\n","[INFO]: Total time spend in procedure: 10.573189735412598 s\n","[INFO]: Total time spend in procedure: 1.6643877029418945 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.476104259490967 s\n","[INFO]: Total time spend in procedure: 1.5205838680267334 s\n","[INFO]: 30 of 74 frames processed.\n","[INFO]: 60 of 74 frames processed.\n","[INFO]: Total time spend in procedure: 3.3511362075805664 s\n","[INFO]: 30 of 160 frames processed.\n","[INFO]: 60 of 160 frames processed.\n","[INFO]: 90 of 160 frames processed.\n","[INFO]: 120 of 160 frames processed.\n","[INFO]: 150 of 160 frames processed.\n","[INFO]: Total time spend in procedure: 7.410356044769287 s\n","[INFO]: Total time spend in procedure: 1.4861867427825928 s\n","[INFO]: 30 of 40 frames processed.\n","[INFO]: Total time spend in procedure: 1.796186923980713 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.461659669876099 s\n","[INFO]: Total time spend in procedure: 1.5547528266906738 s\n","[INFO]: 30 of 110 frames processed.\n","[INFO]: 60 of 110 frames processed.\n","[INFO]: 90 of 110 frames processed.\n","[INFO]: Total time spend in procedure: 5.10157322883606 s\n","[INFO]: Total time spend in procedure: 1.1095209121704102 s\n","[INFO]: 30 of 86 frames processed.\n","[INFO]: 60 of 86 frames processed.\n","[INFO]: Total time spend in procedure: 3.926908493041992 s\n","[INFO]: Total time spend in procedure: 0.8686790466308594 s\n","[INFO]: 30 of 146 frames processed.\n","[INFO]: 60 of 146 frames processed.\n","[INFO]: 90 of 146 frames processed.\n","[INFO]: 120 of 146 frames processed.\n","[INFO]: Total time spend in procedure: 6.793859004974365 s\n","[INFO]: Total time spend in procedure: 1.4363834857940674 s\n","[INFO]: 30 of 990 frames processed.\n","[INFO]: 60 of 990 frames processed.\n","[INFO]: 90 of 990 frames processed.\n","[INFO]: 120 of 990 frames processed.\n","[INFO]: 150 of 990 frames processed.\n","[INFO]: 180 of 990 frames processed.\n","[INFO]: 210 of 990 frames processed.\n","[INFO]: 240 of 990 frames processed.\n","[INFO]: 270 of 990 frames processed.\n","[INFO]: 300 of 990 frames processed.\n","[INFO]: 330 of 990 frames processed.\n","[INFO]: 360 of 990 frames processed.\n","[INFO]: 390 of 990 frames processed.\n","[INFO]: 420 of 990 frames processed.\n","[INFO]: 450 of 990 frames processed.\n","[INFO]: 480 of 990 frames processed.\n","[INFO]: 510 of 990 frames processed.\n","[INFO]: 540 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 26.04969072341919 s\n","[INFO]: 570 of 990 frames processed.\n","[INFO]: 600 of 990 frames processed.\n","[INFO]: 630 of 990 frames processed.\n","[INFO]: 660 of 990 frames processed.\n","[INFO]: 690 of 990 frames processed.\n","[INFO]: 720 of 990 frames processed.\n","[INFO]: 750 of 990 frames processed.\n","[INFO]: 780 of 990 frames processed.\n","[INFO]: 810 of 990 frames processed.\n","[INFO]: 840 of 990 frames processed.\n","[INFO]: 870 of 990 frames processed.\n","[INFO]: 900 of 990 frames processed.\n","[INFO]: 930 of 990 frames processed.\n","[INFO]: 960 of 990 frames processed.\n","[INFO]: 990 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 24.77576971054077 s\n","[INFO]: Total time spend in procedure: 8.396015405654907 s\n","[INFO]: 30 of 236 frames processed.\n","[INFO]: 60 of 236 frames processed.\n","[INFO]: 90 of 236 frames processed.\n","[INFO]: 120 of 236 frames processed.\n","[INFO]: 150 of 236 frames processed.\n","[INFO]: 180 of 236 frames processed.\n","[INFO]: 210 of 236 frames processed.\n","[INFO]: Total time spend in procedure: 10.539573192596436 s\n","[INFO]: Total time spend in procedure: 1.6680126190185547 s\n","[INFO]: 30 of 1200 frames processed.\n","[INFO]: 60 of 1200 frames processed.\n","[INFO]: 90 of 1200 frames processed.\n","[INFO]: 120 of 1200 frames processed.\n","[INFO]: 150 of 1200 frames processed.\n","[INFO]: 180 of 1200 frames processed.\n","[INFO]: 210 of 1200 frames processed.\n","[INFO]: 240 of 1200 frames processed.\n","[INFO]: 270 of 1200 frames processed.\n","[INFO]: 300 of 1200 frames processed.\n","[INFO]: 330 of 1200 frames processed.\n","[INFO]: 360 of 1200 frames processed.\n","[INFO]: 390 of 1200 frames processed.\n","[INFO]: 420 of 1200 frames processed.\n","[INFO]: 450 of 1200 frames processed.\n","[INFO]: 480 of 1200 frames processed.\n","[INFO]: 510 of 1200 frames processed.\n","[INFO]: 540 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 25.942989587783813 s\n","[INFO]: 570 of 1200 frames processed.\n","[INFO]: 600 of 1200 frames processed.\n","[INFO]: 630 of 1200 frames processed.\n","[INFO]: 660 of 1200 frames processed.\n","[INFO]: 690 of 1200 frames processed.\n","[INFO]: 720 of 1200 frames processed.\n","[INFO]: 750 of 1200 frames processed.\n","[INFO]: 780 of 1200 frames processed.\n","[INFO]: 810 of 1200 frames processed.\n","[INFO]: 840 of 1200 frames processed.\n","[INFO]: 870 of 1200 frames processed.\n","[INFO]: 900 of 1200 frames processed.\n","[INFO]: 930 of 1200 frames processed.\n","[INFO]: 960 of 1200 frames processed.\n","[INFO]: 990 of 1200 frames processed.\n","[INFO]: 1020 of 1200 frames processed.\n","[INFO]: 1050 of 1200 frames processed.\n","[INFO]: 1080 of 1200 frames processed.\n","[INFO]: 1110 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 30.362131357192993 s\n","[INFO]: 1140 of 1200 frames processed.\n","[INFO]: 1170 of 1200 frames processed.\n","[INFO]: 1200 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 12.722381591796875 s\n","[INFO]: Total time spend in procedure: 9.923702716827393 s\n","[INFO]: 30 of 600 frames processed.\n","[INFO]: 60 of 600 frames processed.\n","[INFO]: 90 of 600 frames processed.\n","[INFO]: 120 of 600 frames processed.\n","[INFO]: 150 of 600 frames processed.\n","[INFO]: 180 of 600 frames processed.\n","[INFO]: 210 of 600 frames processed.\n","[INFO]: 240 of 600 frames processed.\n","[INFO]: 270 of 600 frames processed.\n","[INFO]: 300 of 600 frames processed.\n","[INFO]: 330 of 600 frames processed.\n","[INFO]: 360 of 600 frames processed.\n","[INFO]: 390 of 600 frames processed.\n","[INFO]: 420 of 600 frames processed.\n","[INFO]: 450 of 600 frames processed.\n","[INFO]: 480 of 600 frames processed.\n","[INFO]: 510 of 600 frames processed.\n","[INFO]: 540 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 26.000218629837036 s\n","[INFO]: 570 of 600 frames processed.\n","[INFO]: 600 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 6.519630670547485 s\n","[INFO]: 30 of 750 frames processed.\n","[INFO]: 60 of 750 frames processed.\n","[INFO]: 90 of 750 frames processed.\n","[INFO]: 120 of 750 frames processed.\n","[INFO]: 150 of 750 frames processed.\n","[INFO]: 180 of 750 frames processed.\n","[INFO]: 210 of 750 frames processed.\n","[INFO]: 240 of 750 frames processed.\n","[INFO]: 270 of 750 frames processed.\n","[INFO]: 300 of 750 frames processed.\n","[INFO]: 330 of 750 frames processed.\n","[INFO]: 360 of 750 frames processed.\n","[INFO]: 390 of 750 frames processed.\n","[INFO]: 420 of 750 frames processed.\n","[INFO]: 450 of 750 frames processed.\n","[INFO]: 480 of 750 frames processed.\n","[INFO]: 510 of 750 frames processed.\n","[INFO]: 540 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 25.83962869644165 s\n","[INFO]: 570 of 750 frames processed.\n","[INFO]: 600 of 750 frames processed.\n","[INFO]: 630 of 750 frames processed.\n","[INFO]: 660 of 750 frames processed.\n","[INFO]: 690 of 750 frames processed.\n","[INFO]: 720 of 750 frames processed.\n","[INFO]: 750 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 13.365288972854614 s\n","[INFO]: Total time spend in procedure: 6.390058517456055 s\n","[INFO]: 30 of 900 frames processed.\n","[INFO]: 60 of 900 frames processed.\n","[INFO]: 90 of 900 frames processed.\n","[INFO]: 120 of 900 frames processed.\n","[INFO]: 150 of 900 frames processed.\n","[INFO]: 180 of 900 frames processed.\n","[INFO]: 210 of 900 frames processed.\n","[INFO]: 240 of 900 frames processed.\n","[INFO]: 270 of 900 frames processed.\n","[INFO]: 300 of 900 frames processed.\n","[INFO]: 330 of 900 frames processed.\n","[INFO]: 360 of 900 frames processed.\n","[INFO]: 390 of 900 frames processed.\n","[INFO]: 420 of 900 frames processed.\n","[INFO]: 450 of 900 frames processed.\n","[INFO]: 480 of 900 frames processed.\n","[INFO]: 510 of 900 frames processed.\n","[INFO]: 540 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 26.168720960617065 s\n","[INFO]: 570 of 900 frames processed.\n","[INFO]: 600 of 900 frames processed.\n","[INFO]: 630 of 900 frames processed.\n","[INFO]: 660 of 900 frames processed.\n","[INFO]: 690 of 900 frames processed.\n","[INFO]: 720 of 900 frames processed.\n","[INFO]: 750 of 900 frames processed.\n","[INFO]: 780 of 900 frames processed.\n","[INFO]: 810 of 900 frames processed.\n","[INFO]: 840 of 900 frames processed.\n","[INFO]: 870 of 900 frames processed.\n","[INFO]: 900 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 20.61225414276123 s\n","[INFO]: Total time spend in procedure: 7.629982233047485 s\n","[INFO]: 30 of 780 frames processed.\n","[INFO]: 60 of 780 frames processed.\n","[INFO]: 90 of 780 frames processed.\n","[INFO]: 120 of 780 frames processed.\n","[INFO]: 150 of 780 frames processed.\n","[INFO]: 180 of 780 frames processed.\n","[INFO]: 210 of 780 frames processed.\n","[INFO]: 240 of 780 frames processed.\n","[INFO]: 270 of 780 frames processed.\n","[INFO]: 300 of 780 frames processed.\n","[INFO]: 330 of 780 frames processed.\n","[INFO]: 360 of 780 frames processed.\n","[INFO]: 390 of 780 frames processed.\n","[INFO]: 420 of 780 frames processed.\n","[INFO]: 450 of 780 frames processed.\n","[INFO]: 480 of 780 frames processed.\n","[INFO]: 510 of 780 frames processed.\n","[INFO]: 540 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 25.92473292350769 s\n","[INFO]: 570 of 780 frames processed.\n","[INFO]: 600 of 780 frames processed.\n","[INFO]: 630 of 780 frames processed.\n","[INFO]: 660 of 780 frames processed.\n","[INFO]: 690 of 780 frames processed.\n","[INFO]: 720 of 780 frames processed.\n","[INFO]: 750 of 780 frames processed.\n","[INFO]: 780 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 14.899633884429932 s\n","[INFO]: Total time spend in procedure: 6.6308369636535645 s\n","[INFO]: 30 of 240 frames processed.\n","[INFO]: 60 of 240 frames processed.\n","[INFO]: 90 of 240 frames processed.\n","[INFO]: 120 of 240 frames processed.\n","[INFO]: 150 of 240 frames processed.\n","[INFO]: 180 of 240 frames processed.\n","[INFO]: 210 of 240 frames processed.\n","[INFO]: 240 of 240 frames processed.\n","[INFO]: Total time spend in procedure: 11.39040207862854 s\n","[INFO]: Total time spend in procedure: 2.3311314582824707 s\n","[INFO]: 30 of 146 frames processed.\n","[INFO]: 60 of 146 frames processed.\n","[INFO]: 90 of 146 frames processed.\n","[INFO]: 120 of 146 frames processed.\n","[INFO]: Total time spend in procedure: 6.82333779335022 s\n","[INFO]: Total time spend in procedure: 1.4368805885314941 s\n","[INFO]: 30 of 160 frames processed.\n","[INFO]: 60 of 160 frames processed.\n","[INFO]: 90 of 160 frames processed.\n","[INFO]: 120 of 160 frames processed.\n","[INFO]: 150 of 160 frames processed.\n","[INFO]: Total time spend in procedure: 7.406843662261963 s\n","[INFO]: Total time spend in procedure: 1.4701387882232666 s\n","[INFO]: 30 of 110 frames processed.\n","[INFO]: 60 of 110 frames processed.\n","[INFO]: 90 of 110 frames processed.\n","[INFO]: Total time spend in procedure: 5.101787805557251 s\n","[INFO]: Total time spend in procedure: 1.1197376251220703 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.4550230503082275 s\n","[INFO]: Total time spend in procedure: 1.5649030208587646 s\n","[INFO]: 30 of 74 frames processed.\n","[INFO]: 60 of 74 frames processed.\n","[INFO]: Total time spend in procedure: 3.394343376159668 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.4459850788116455 s\n","[INFO]: Total time spend in procedure: 1.5131118297576904 s\n","[INFO]: 30 of 40 frames processed.\n","[INFO]: Total time spend in procedure: 1.7856192588806152 s\n","[INFO]: 30 of 86 frames processed.\n","[INFO]: 60 of 86 frames processed.\n","[INFO]: Total time spend in procedure: 3.9290125370025635 s\n","[INFO]: Total time spend in procedure: 0.8722438812255859 s\n","[INFO]: 30 of 1200 frames processed.\n","[INFO]: 60 of 1200 frames processed.\n","[INFO]: 90 of 1200 frames processed.\n","[INFO]: 120 of 1200 frames processed.\n","[INFO]: 150 of 1200 frames processed.\n","[INFO]: 180 of 1200 frames processed.\n","[INFO]: 210 of 1200 frames processed.\n","[INFO]: 240 of 1200 frames processed.\n","[INFO]: 270 of 1200 frames processed.\n","[INFO]: 300 of 1200 frames processed.\n","[INFO]: 330 of 1200 frames processed.\n","[INFO]: 360 of 1200 frames processed.\n","[INFO]: 390 of 1200 frames processed.\n","[INFO]: 420 of 1200 frames processed.\n","[INFO]: 450 of 1200 frames processed.\n","[INFO]: 480 of 1200 frames processed.\n","[INFO]: 510 of 1200 frames processed.\n","[INFO]: 540 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 25.854222059249878 s\n","[INFO]: 570 of 1200 frames processed.\n","[INFO]: 600 of 1200 frames processed.\n","[INFO]: 630 of 1200 frames processed.\n","[INFO]: 660 of 1200 frames processed.\n","[INFO]: 690 of 1200 frames processed.\n","[INFO]: 720 of 1200 frames processed.\n","[INFO]: 750 of 1200 frames processed.\n","[INFO]: 780 of 1200 frames processed.\n","[INFO]: 810 of 1200 frames processed.\n","[INFO]: 840 of 1200 frames processed.\n","[INFO]: 870 of 1200 frames processed.\n","[INFO]: 900 of 1200 frames processed.\n","[INFO]: 930 of 1200 frames processed.\n","[INFO]: 960 of 1200 frames processed.\n","[INFO]: 990 of 1200 frames processed.\n","[INFO]: 1020 of 1200 frames processed.\n","[INFO]: 1050 of 1200 frames processed.\n","[INFO]: 1080 of 1200 frames processed.\n","[INFO]: 1110 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 30.355414628982544 s\n","[INFO]: 1140 of 1200 frames processed.\n","[INFO]: 1170 of 1200 frames processed.\n","[INFO]: 1200 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 12.860302925109863 s\n","[INFO]: Total time spend in procedure: 9.848037481307983 s\n","[INFO]: 30 of 990 frames processed.\n","[INFO]: 60 of 990 frames processed.\n","[INFO]: 90 of 990 frames processed.\n","[INFO]: 120 of 990 frames processed.\n","[INFO]: 150 of 990 frames processed.\n","[INFO]: 180 of 990 frames processed.\n","[INFO]: 210 of 990 frames processed.\n","[INFO]: 240 of 990 frames processed.\n","[INFO]: 270 of 990 frames processed.\n","[INFO]: 300 of 990 frames processed.\n","[INFO]: 330 of 990 frames processed.\n","[INFO]: 360 of 990 frames processed.\n","[INFO]: 390 of 990 frames processed.\n","[INFO]: 420 of 990 frames processed.\n","[INFO]: 450 of 990 frames processed.\n","[INFO]: 480 of 990 frames processed.\n","[INFO]: 510 of 990 frames processed.\n","[INFO]: 540 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 26.11984610557556 s\n","[INFO]: 570 of 990 frames processed.\n","[INFO]: 600 of 990 frames processed.\n","[INFO]: 630 of 990 frames processed.\n","[INFO]: 660 of 990 frames processed.\n","[INFO]: 690 of 990 frames processed.\n","[INFO]: 720 of 990 frames processed.\n","[INFO]: 750 of 990 frames processed.\n","[INFO]: 780 of 990 frames processed.\n","[INFO]: 810 of 990 frames processed.\n","[INFO]: 840 of 990 frames processed.\n","[INFO]: 870 of 990 frames processed.\n","[INFO]: 900 of 990 frames processed.\n","[INFO]: 930 of 990 frames processed.\n","[INFO]: 960 of 990 frames processed.\n","[INFO]: 990 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 24.774551153182983 s\n","[INFO]: Total time spend in procedure: 8.513079643249512 s\n","[INFO]: 30 of 236 frames processed.\n","[INFO]: 60 of 236 frames processed.\n","[INFO]: 90 of 236 frames processed.\n","[INFO]: 120 of 236 frames processed.\n","[INFO]: 150 of 236 frames processed.\n","[INFO]: 180 of 236 frames processed.\n","[INFO]: 210 of 236 frames processed.\n","[INFO]: Total time spend in procedure: 10.547943830490112 s\n","[INFO]: Total time spend in procedure: 1.6978380680084229 s\n","[INFO]: 30 of 600 frames processed.\n","[INFO]: 60 of 600 frames processed.\n","[INFO]: 90 of 600 frames processed.\n","[INFO]: 120 of 600 frames processed.\n","[INFO]: 150 of 600 frames processed.\n","[INFO]: 180 of 600 frames processed.\n","[INFO]: 210 of 600 frames processed.\n","[INFO]: 240 of 600 frames processed.\n","[INFO]: 270 of 600 frames processed.\n","[INFO]: 300 of 600 frames processed.\n","[INFO]: 330 of 600 frames processed.\n","[INFO]: 360 of 600 frames processed.\n","[INFO]: 390 of 600 frames processed.\n","[INFO]: 420 of 600 frames processed.\n","[INFO]: 450 of 600 frames processed.\n","[INFO]: 480 of 600 frames processed.\n","[INFO]: 510 of 600 frames processed.\n","[INFO]: 540 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 25.99660563468933 s\n","[INFO]: 570 of 600 frames processed.\n","[INFO]: 600 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 6.524362325668335 s\n","[INFO]: 30 of 750 frames processed.\n","[INFO]: 60 of 750 frames processed.\n","[INFO]: 90 of 750 frames processed.\n","[INFO]: 120 of 750 frames processed.\n","[INFO]: 150 of 750 frames processed.\n","[INFO]: 180 of 750 frames processed.\n","[INFO]: 210 of 750 frames processed.\n","[INFO]: 240 of 750 frames processed.\n","[INFO]: 270 of 750 frames processed.\n","[INFO]: 300 of 750 frames processed.\n","[INFO]: 330 of 750 frames processed.\n","[INFO]: 360 of 750 frames processed.\n","[INFO]: 390 of 750 frames processed.\n","[INFO]: 420 of 750 frames processed.\n","[INFO]: 450 of 750 frames processed.\n","[INFO]: 480 of 750 frames processed.\n","[INFO]: 510 of 750 frames processed.\n","[INFO]: 540 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 25.80186414718628 s\n","[INFO]: 570 of 750 frames processed.\n","[INFO]: 600 of 750 frames processed.\n","[INFO]: 630 of 750 frames processed.\n","[INFO]: 660 of 750 frames processed.\n","[INFO]: 690 of 750 frames processed.\n","[INFO]: 720 of 750 frames processed.\n","[INFO]: 750 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 13.408258438110352 s\n","[INFO]: Total time spend in procedure: 6.270526170730591 s\n","[INFO]: 30 of 240 frames processed.\n","[INFO]: 60 of 240 frames processed.\n","[INFO]: 90 of 240 frames processed.\n","[INFO]: 120 of 240 frames processed.\n","[INFO]: 150 of 240 frames processed.\n","[INFO]: 180 of 240 frames processed.\n","[INFO]: 210 of 240 frames processed.\n","[INFO]: 240 of 240 frames processed.\n","[INFO]: Total time spend in procedure: 11.391456365585327 s\n","[INFO]: Total time spend in procedure: 2.320235013961792 s\n","[INFO]: 30 of 780 frames processed.\n","[INFO]: 60 of 780 frames processed.\n","[INFO]: 90 of 780 frames processed.\n","[INFO]: 120 of 780 frames processed.\n","[INFO]: 150 of 780 frames processed.\n","[INFO]: 180 of 780 frames processed.\n","[INFO]: 210 of 780 frames processed.\n","[INFO]: 240 of 780 frames processed.\n","[INFO]: 270 of 780 frames processed.\n","[INFO]: 300 of 780 frames processed.\n","[INFO]: 330 of 780 frames processed.\n","[INFO]: 360 of 780 frames processed.\n","[INFO]: 390 of 780 frames processed.\n","[INFO]: 420 of 780 frames processed.\n","[INFO]: 450 of 780 frames processed.\n","[INFO]: 480 of 780 frames processed.\n","[INFO]: 510 of 780 frames processed.\n","[INFO]: 540 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 25.936551094055176 s\n","[INFO]: 570 of 780 frames processed.\n","[INFO]: 600 of 780 frames processed.\n","[INFO]: 630 of 780 frames processed.\n","[INFO]: 660 of 780 frames processed.\n","[INFO]: 690 of 780 frames processed.\n","[INFO]: 720 of 780 frames processed.\n","[INFO]: 750 of 780 frames processed.\n","[INFO]: 780 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 14.820422172546387 s\n","[INFO]: Total time spend in procedure: 6.68563985824585 s\n","[INFO]: 30 of 900 frames processed.\n","[INFO]: 60 of 900 frames processed.\n","[INFO]: 90 of 900 frames processed.\n","[INFO]: 120 of 900 frames processed.\n","[INFO]: 150 of 900 frames processed.\n","[INFO]: 180 of 900 frames processed.\n","[INFO]: 210 of 900 frames processed.\n","[INFO]: 240 of 900 frames processed.\n","[INFO]: 270 of 900 frames processed.\n","[INFO]: 300 of 900 frames processed.\n","[INFO]: 330 of 900 frames processed.\n","[INFO]: 360 of 900 frames processed.\n","[INFO]: 390 of 900 frames processed.\n","[INFO]: 420 of 900 frames processed.\n","[INFO]: 450 of 900 frames processed.\n","[INFO]: 480 of 900 frames processed.\n","[INFO]: 510 of 900 frames processed.\n","[INFO]: 540 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 26.219130992889404 s\n","[INFO]: 570 of 900 frames processed.\n","[INFO]: 600 of 900 frames processed.\n","[INFO]: 630 of 900 frames processed.\n","[INFO]: 660 of 900 frames processed.\n","[INFO]: 690 of 900 frames processed.\n","[INFO]: 720 of 900 frames processed.\n","[INFO]: 750 of 900 frames processed.\n","[INFO]: 780 of 900 frames processed.\n","[INFO]: 810 of 900 frames processed.\n","[INFO]: 840 of 900 frames processed.\n","[INFO]: 870 of 900 frames processed.\n","[INFO]: 900 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 20.707109212875366 s\n","[INFO]: Total time spend in procedure: 7.661383867263794 s\n","[INFO]: 30 of 74 frames processed.\n","[INFO]: 60 of 74 frames processed.\n","[INFO]: Total time spend in procedure: 3.388002872467041 s\n","[INFO]: 30 of 40 frames processed.\n","[INFO]: Total time spend in procedure: 1.7900032997131348 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.481767654418945 s\n","[INFO]: Total time spend in procedure: 1.529994010925293 s\n","[INFO]: 30 of 146 frames processed.\n","[INFO]: 60 of 146 frames processed.\n","[INFO]: 90 of 146 frames processed.\n","[INFO]: 120 of 146 frames processed.\n","[INFO]: Total time spend in procedure: 6.788227796554565 s\n","[INFO]: Total time spend in procedure: 1.4646720886230469 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.471334934234619 s\n","[INFO]: Total time spend in procedure: 1.5691699981689453 s\n","[INFO]: 30 of 86 frames processed.\n","[INFO]: 60 of 86 frames processed.\n","[INFO]: Total time spend in procedure: 3.9552536010742188 s\n","[INFO]: Total time spend in procedure: 0.8728430271148682 s\n","[INFO]: 30 of 110 frames processed.\n","[INFO]: 60 of 110 frames processed.\n","[INFO]: 90 of 110 frames processed.\n","[INFO]: Total time spend in procedure: 5.128173828125 s\n","[INFO]: Total time spend in procedure: 1.1351385116577148 s\n","[INFO]: 30 of 160 frames processed.\n","[INFO]: 60 of 160 frames processed.\n","[INFO]: 90 of 160 frames processed.\n","[INFO]: 120 of 160 frames processed.\n","[INFO]: 150 of 160 frames processed.\n","[INFO]: Total time spend in procedure: 7.398756980895996 s\n","[INFO]: Total time spend in procedure: 1.505929708480835 s\n","[INFO]: 30 of 600 frames processed.\n","[INFO]: 60 of 600 frames processed.\n","[INFO]: 90 of 600 frames processed.\n","[INFO]: 120 of 600 frames processed.\n","[INFO]: 150 of 600 frames processed.\n","[INFO]: 180 of 600 frames processed.\n","[INFO]: 210 of 600 frames processed.\n","[INFO]: 240 of 600 frames processed.\n","[INFO]: 270 of 600 frames processed.\n","[INFO]: 300 of 600 frames processed.\n","[INFO]: 330 of 600 frames processed.\n","[INFO]: 360 of 600 frames processed.\n","[INFO]: 390 of 600 frames processed.\n","[INFO]: 420 of 600 frames processed.\n","[INFO]: 450 of 600 frames processed.\n","[INFO]: 480 of 600 frames processed.\n","[INFO]: 510 of 600 frames processed.\n","[INFO]: 540 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 26.085620880126953 s\n","[INFO]: 570 of 600 frames processed.\n","[INFO]: 600 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 6.644741535186768 s\n","[INFO]: 30 of 780 frames processed.\n","[INFO]: 60 of 780 frames processed.\n","[INFO]: 90 of 780 frames processed.\n","[INFO]: 120 of 780 frames processed.\n","[INFO]: 150 of 780 frames processed.\n","[INFO]: 180 of 780 frames processed.\n","[INFO]: 210 of 780 frames processed.\n","[INFO]: 240 of 780 frames processed.\n","[INFO]: 270 of 780 frames processed.\n","[INFO]: 300 of 780 frames processed.\n","[INFO]: 330 of 780 frames processed.\n","[INFO]: 360 of 780 frames processed.\n","[INFO]: 390 of 780 frames processed.\n","[INFO]: 420 of 780 frames processed.\n","[INFO]: 450 of 780 frames processed.\n","[INFO]: 480 of 780 frames processed.\n","[INFO]: 510 of 780 frames processed.\n","[INFO]: 540 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 26.252410650253296 s\n","[INFO]: 570 of 780 frames processed.\n","[INFO]: 600 of 780 frames processed.\n","[INFO]: 630 of 780 frames processed.\n","[INFO]: 660 of 780 frames processed.\n","[INFO]: 690 of 780 frames processed.\n","[INFO]: 720 of 780 frames processed.\n","[INFO]: 750 of 780 frames processed.\n","[INFO]: 780 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 15.22268009185791 s\n","[INFO]: Total time spend in procedure: 6.958766222000122 s\n","[INFO]: 30 of 900 frames processed.\n","[INFO]: 60 of 900 frames processed.\n","[INFO]: 90 of 900 frames processed.\n","[INFO]: 120 of 900 frames processed.\n","[INFO]: 150 of 900 frames processed.\n","[INFO]: 180 of 900 frames processed.\n","[INFO]: 210 of 900 frames processed.\n","[INFO]: 240 of 900 frames processed.\n","[INFO]: 270 of 900 frames processed.\n","[INFO]: 300 of 900 frames processed.\n","[INFO]: 330 of 900 frames processed.\n","[INFO]: 360 of 900 frames processed.\n","[INFO]: 390 of 900 frames processed.\n","[INFO]: 420 of 900 frames processed.\n","[INFO]: 450 of 900 frames processed.\n","[INFO]: 480 of 900 frames processed.\n","[INFO]: 510 of 900 frames processed.\n","[INFO]: 540 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 26.500476837158203 s\n","[INFO]: 570 of 900 frames processed.\n","[INFO]: 600 of 900 frames processed.\n","[INFO]: 630 of 900 frames processed.\n","[INFO]: 660 of 900 frames processed.\n","[INFO]: 690 of 900 frames processed.\n","[INFO]: 720 of 900 frames processed.\n","[INFO]: 750 of 900 frames processed.\n","[INFO]: 780 of 900 frames processed.\n","[INFO]: 810 of 900 frames processed.\n","[INFO]: 840 of 900 frames processed.\n","[INFO]: 870 of 900 frames processed.\n","[INFO]: 900 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 21.08588194847107 s\n","[INFO]: Total time spend in procedure: 8.086852073669434 s\n","[INFO]: 30 of 990 frames processed.\n","[INFO]: 60 of 990 frames processed.\n","[INFO]: 90 of 990 frames processed.\n","[INFO]: 120 of 990 frames processed.\n","[INFO]: 150 of 990 frames processed.\n","[INFO]: 180 of 990 frames processed.\n","[INFO]: 210 of 990 frames processed.\n","[INFO]: 240 of 990 frames processed.\n","[INFO]: 270 of 990 frames processed.\n","[INFO]: 300 of 990 frames processed.\n","[INFO]: 330 of 990 frames processed.\n","[INFO]: 360 of 990 frames processed.\n","[INFO]: 390 of 990 frames processed.\n","[INFO]: 420 of 990 frames processed.\n","[INFO]: 450 of 990 frames processed.\n","[INFO]: 480 of 990 frames processed.\n","[INFO]: 510 of 990 frames processed.\n","[INFO]: 540 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 26.4907968044281 s\n","[INFO]: 570 of 990 frames processed.\n","[INFO]: 600 of 990 frames processed.\n","[INFO]: 630 of 990 frames processed.\n","[INFO]: 660 of 990 frames processed.\n","[INFO]: 690 of 990 frames processed.\n","[INFO]: 720 of 990 frames processed.\n","[INFO]: 750 of 990 frames processed.\n","[INFO]: 780 of 990 frames processed.\n","[INFO]: 810 of 990 frames processed.\n","[INFO]: 840 of 990 frames processed.\n","[INFO]: 870 of 990 frames processed.\n","[INFO]: 900 of 990 frames processed.\n","[INFO]: 930 of 990 frames processed.\n","[INFO]: 960 of 990 frames processed.\n","[INFO]: 990 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 25.15154504776001 s\n","[INFO]: Total time spend in procedure: 8.598684072494507 s\n","[INFO]: 30 of 1200 frames processed.\n","[INFO]: 60 of 1200 frames processed.\n","[INFO]: 90 of 1200 frames processed.\n","[INFO]: 120 of 1200 frames processed.\n","[INFO]: 150 of 1200 frames processed.\n","[INFO]: 180 of 1200 frames processed.\n","[INFO]: 210 of 1200 frames processed.\n","[INFO]: 240 of 1200 frames processed.\n","[INFO]: 270 of 1200 frames processed.\n","[INFO]: 300 of 1200 frames processed.\n","[INFO]: 330 of 1200 frames processed.\n","[INFO]: 360 of 1200 frames processed.\n","[INFO]: 390 of 1200 frames processed.\n","[INFO]: 420 of 1200 frames processed.\n","[INFO]: 450 of 1200 frames processed.\n","[INFO]: 480 of 1200 frames processed.\n","[INFO]: 510 of 1200 frames processed.\n","[INFO]: 540 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 26.07557201385498 s\n","[INFO]: 570 of 1200 frames processed.\n","[INFO]: 600 of 1200 frames processed.\n","[INFO]: 630 of 1200 frames processed.\n","[INFO]: 660 of 1200 frames processed.\n","[INFO]: 690 of 1200 frames processed.\n","[INFO]: 720 of 1200 frames processed.\n","[INFO]: 750 of 1200 frames processed.\n","[INFO]: 780 of 1200 frames processed.\n","[INFO]: 810 of 1200 frames processed.\n","[INFO]: 840 of 1200 frames processed.\n","[INFO]: 870 of 1200 frames processed.\n","[INFO]: 900 of 1200 frames processed.\n","[INFO]: 930 of 1200 frames processed.\n","[INFO]: 960 of 1200 frames processed.\n","[INFO]: 990 of 1200 frames processed.\n","[INFO]: 1020 of 1200 frames processed.\n","[INFO]: 1050 of 1200 frames processed.\n","[INFO]: 1080 of 1200 frames processed.\n","[INFO]: 1110 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 30.620637893676758 s\n","[INFO]: 1140 of 1200 frames processed.\n","[INFO]: 1170 of 1200 frames processed.\n","[INFO]: 1200 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 12.909312725067139 s\n","[INFO]: Total time spend in procedure: 9.935701370239258 s\n","[INFO]: 30 of 750 frames processed.\n","[INFO]: 60 of 750 frames processed.\n","[INFO]: 90 of 750 frames processed.\n","[INFO]: 120 of 750 frames processed.\n","[INFO]: 150 of 750 frames processed.\n","[INFO]: 180 of 750 frames processed.\n","[INFO]: 210 of 750 frames processed.\n","[INFO]: 240 of 750 frames processed.\n","[INFO]: 270 of 750 frames processed.\n","[INFO]: 300 of 750 frames processed.\n","[INFO]: 330 of 750 frames processed.\n","[INFO]: 360 of 750 frames processed.\n","[INFO]: 390 of 750 frames processed.\n","[INFO]: 420 of 750 frames processed.\n","[INFO]: 450 of 750 frames processed.\n","[INFO]: 480 of 750 frames processed.\n","[INFO]: 510 of 750 frames processed.\n","[INFO]: 540 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 26.071505308151245 s\n","[INFO]: 570 of 750 frames processed.\n","[INFO]: 600 of 750 frames processed.\n","[INFO]: 630 of 750 frames processed.\n","[INFO]: 660 of 750 frames processed.\n","[INFO]: 690 of 750 frames processed.\n","[INFO]: 720 of 750 frames processed.\n","[INFO]: 750 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 13.482747554779053 s\n","[INFO]: Total time spend in procedure: 6.343093633651733 s\n","[INFO]: 30 of 236 frames processed.\n","[INFO]: 60 of 236 frames processed.\n","[INFO]: 90 of 236 frames processed.\n","[INFO]: 120 of 236 frames processed.\n","[INFO]: 150 of 236 frames processed.\n","[INFO]: 180 of 236 frames processed.\n","[INFO]: 210 of 236 frames processed.\n","[INFO]: Total time spend in procedure: 10.562039136886597 s\n","[INFO]: Total time spend in procedure: 1.6882884502410889 s\n","[INFO]: 30 of 240 frames processed.\n","[INFO]: 60 of 240 frames processed.\n","[INFO]: 90 of 240 frames processed.\n","[INFO]: 120 of 240 frames processed.\n","[INFO]: 150 of 240 frames processed.\n","[INFO]: 180 of 240 frames processed.\n","[INFO]: 210 of 240 frames processed.\n","[INFO]: 240 of 240 frames processed.\n","[INFO]: Total time spend in procedure: 11.470541715621948 s\n","[INFO]: Total time spend in procedure: 2.4459471702575684 s\n","[INFO]: 30 of 160 frames processed.\n","[INFO]: 60 of 160 frames processed.\n","[INFO]: 90 of 160 frames processed.\n","[INFO]: 120 of 160 frames processed.\n","[INFO]: 150 of 160 frames processed.\n","[INFO]: Total time spend in procedure: 7.4984822273254395 s\n","[INFO]: Total time spend in procedure: 1.506035566329956 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.5142822265625 s\n","[INFO]: Total time spend in procedure: 1.5893242359161377 s\n","[INFO]: 30 of 40 frames processed.\n","[INFO]: Total time spend in procedure: 1.798448085784912 s\n","[INFO]: 30 of 86 frames processed.\n","[INFO]: 60 of 86 frames processed.\n","[INFO]: Total time spend in procedure: 3.944350481033325 s\n","[INFO]: Total time spend in procedure: 0.899611234664917 s\n","[INFO]: 30 of 146 frames processed.\n","[INFO]: 60 of 146 frames processed.\n","[INFO]: 90 of 146 frames processed.\n","[INFO]: 120 of 146 frames processed.\n","[INFO]: Total time spend in procedure: 6.854197263717651 s\n","[INFO]: Total time spend in procedure: 1.48671293258667 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.469374895095825 s\n","[INFO]: Total time spend in procedure: 1.5906012058258057 s\n","[INFO]: 30 of 74 frames processed.\n","[INFO]: 60 of 74 frames processed.\n","[INFO]: Total time spend in procedure: 3.398179769515991 s\n","[INFO]: 30 of 110 frames processed.\n","[INFO]: 60 of 110 frames processed.\n","[INFO]: 90 of 110 frames processed.\n","[INFO]: Total time spend in procedure: 5.120884656906128 s\n","[INFO]: Total time spend in procedure: 1.141153335571289 s\n","[INFO]: 30 of 750 frames processed.\n","[INFO]: 60 of 750 frames processed.\n","[INFO]: 90 of 750 frames processed.\n","[INFO]: 120 of 750 frames processed.\n","[INFO]: 150 of 750 frames processed.\n","[INFO]: 180 of 750 frames processed.\n","[INFO]: 210 of 750 frames processed.\n","[INFO]: 240 of 750 frames processed.\n","[INFO]: 270 of 750 frames processed.\n","[INFO]: 300 of 750 frames processed.\n","[INFO]: 330 of 750 frames processed.\n","[INFO]: 360 of 750 frames processed.\n","[INFO]: 390 of 750 frames processed.\n","[INFO]: 420 of 750 frames processed.\n","[INFO]: 450 of 750 frames processed.\n","[INFO]: 480 of 750 frames processed.\n","[INFO]: 510 of 750 frames processed.\n","[INFO]: 540 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 25.952030658721924 s\n","[INFO]: 570 of 750 frames processed.\n","[INFO]: 600 of 750 frames processed.\n","[INFO]: 630 of 750 frames processed.\n","[INFO]: 660 of 750 frames processed.\n","[INFO]: 690 of 750 frames processed.\n","[INFO]: 720 of 750 frames processed.\n","[INFO]: 750 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 13.488218069076538 s\n","[INFO]: Total time spend in procedure: 6.528526306152344 s\n","[INFO]: 30 of 600 frames processed.\n","[INFO]: 60 of 600 frames processed.\n","[INFO]: 90 of 600 frames processed.\n","[INFO]: 120 of 600 frames processed.\n","[INFO]: 150 of 600 frames processed.\n","[INFO]: 180 of 600 frames processed.\n","[INFO]: 210 of 600 frames processed.\n","[INFO]: 240 of 600 frames processed.\n","[INFO]: 270 of 600 frames processed.\n","[INFO]: 300 of 600 frames processed.\n","[INFO]: 330 of 600 frames processed.\n","[INFO]: 360 of 600 frames processed.\n","[INFO]: 390 of 600 frames processed.\n","[INFO]: 420 of 600 frames processed.\n","[INFO]: 450 of 600 frames processed.\n","[INFO]: 480 of 600 frames processed.\n","[INFO]: 510 of 600 frames processed.\n","[INFO]: 540 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 26.191521883010864 s\n","[INFO]: 570 of 600 frames processed.\n","[INFO]: 600 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 6.6364617347717285 s\n","[INFO]: 30 of 240 frames processed.\n","[INFO]: 60 of 240 frames processed.\n","[INFO]: 90 of 240 frames processed.\n","[INFO]: 120 of 240 frames processed.\n","[INFO]: 150 of 240 frames processed.\n","[INFO]: 180 of 240 frames processed.\n","[INFO]: 210 of 240 frames processed.\n","[INFO]: 240 of 240 frames processed.\n","[INFO]: Total time spend in procedure: 11.4047110080719 s\n","[INFO]: Total time spend in procedure: 2.3935391902923584 s\n","[INFO]: 30 of 780 frames processed.\n","[INFO]: 60 of 780 frames processed.\n","[INFO]: 90 of 780 frames processed.\n","[INFO]: 120 of 780 frames processed.\n","[INFO]: 150 of 780 frames processed.\n","[INFO]: 180 of 780 frames processed.\n","[INFO]: 210 of 780 frames processed.\n","[INFO]: 240 of 780 frames processed.\n","[INFO]: 270 of 780 frames processed.\n","[INFO]: 300 of 780 frames processed.\n","[INFO]: 330 of 780 frames processed.\n","[INFO]: 360 of 780 frames processed.\n","[INFO]: 390 of 780 frames processed.\n","[INFO]: 420 of 780 frames processed.\n","[INFO]: 450 of 780 frames processed.\n","[INFO]: 480 of 780 frames processed.\n","[INFO]: 510 of 780 frames processed.\n","[INFO]: 540 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 26.106044054031372 s\n","[INFO]: 570 of 780 frames processed.\n","[INFO]: 600 of 780 frames processed.\n","[INFO]: 630 of 780 frames processed.\n","[INFO]: 660 of 780 frames processed.\n","[INFO]: 690 of 780 frames processed.\n","[INFO]: 720 of 780 frames processed.\n","[INFO]: 750 of 780 frames processed.\n","[INFO]: 780 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 15.031829833984375 s\n","[INFO]: Total time spend in procedure: 6.758102178573608 s\n","[INFO]: 30 of 990 frames processed.\n","[INFO]: 60 of 990 frames processed.\n","[INFO]: 90 of 990 frames processed.\n","[INFO]: 120 of 990 frames processed.\n","[INFO]: 150 of 990 frames processed.\n","[INFO]: 180 of 990 frames processed.\n","[INFO]: 210 of 990 frames processed.\n","[INFO]: 240 of 990 frames processed.\n","[INFO]: 270 of 990 frames processed.\n","[INFO]: 300 of 990 frames processed.\n","[INFO]: 330 of 990 frames processed.\n","[INFO]: 360 of 990 frames processed.\n","[INFO]: 390 of 990 frames processed.\n","[INFO]: 420 of 990 frames processed.\n","[INFO]: 450 of 990 frames processed.\n","[INFO]: 480 of 990 frames processed.\n","[INFO]: 510 of 990 frames processed.\n","[INFO]: 540 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 26.271188735961914 s\n","[INFO]: 570 of 990 frames processed.\n","[INFO]: 600 of 990 frames processed.\n","[INFO]: 630 of 990 frames processed.\n","[INFO]: 660 of 990 frames processed.\n","[INFO]: 690 of 990 frames processed.\n","[INFO]: 720 of 990 frames processed.\n","[INFO]: 750 of 990 frames processed.\n","[INFO]: 780 of 990 frames processed.\n","[INFO]: 810 of 990 frames processed.\n","[INFO]: 840 of 990 frames processed.\n","[INFO]: 870 of 990 frames processed.\n","[INFO]: 900 of 990 frames processed.\n","[INFO]: 930 of 990 frames processed.\n","[INFO]: 960 of 990 frames processed.\n","[INFO]: 990 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 24.879903316497803 s\n","[INFO]: Total time spend in procedure: 8.62593388557434 s\n","[INFO]: 30 of 1200 frames processed.\n","[INFO]: 60 of 1200 frames processed.\n","[INFO]: 90 of 1200 frames processed.\n","[INFO]: 120 of 1200 frames processed.\n","[INFO]: 150 of 1200 frames processed.\n","[INFO]: 180 of 1200 frames processed.\n","[INFO]: 210 of 1200 frames processed.\n","[INFO]: 240 of 1200 frames processed.\n","[INFO]: 270 of 1200 frames processed.\n","[INFO]: 300 of 1200 frames processed.\n","[INFO]: 330 of 1200 frames processed.\n","[INFO]: 360 of 1200 frames processed.\n","[INFO]: 390 of 1200 frames processed.\n","[INFO]: 420 of 1200 frames processed.\n","[INFO]: 450 of 1200 frames processed.\n","[INFO]: 480 of 1200 frames processed.\n","[INFO]: 510 of 1200 frames processed.\n","[INFO]: 540 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 25.99239683151245 s\n","[INFO]: 570 of 1200 frames processed.\n","[INFO]: 600 of 1200 frames processed.\n","[INFO]: 630 of 1200 frames processed.\n","[INFO]: 660 of 1200 frames processed.\n","[INFO]: 690 of 1200 frames processed.\n","[INFO]: 720 of 1200 frames processed.\n","[INFO]: 750 of 1200 frames processed.\n","[INFO]: 780 of 1200 frames processed.\n","[INFO]: 810 of 1200 frames processed.\n","[INFO]: 840 of 1200 frames processed.\n","[INFO]: 870 of 1200 frames processed.\n","[INFO]: 900 of 1200 frames processed.\n","[INFO]: 930 of 1200 frames processed.\n","[INFO]: 960 of 1200 frames processed.\n","[INFO]: 990 of 1200 frames processed.\n","[INFO]: 1020 of 1200 frames processed.\n","[INFO]: 1050 of 1200 frames processed.\n","[INFO]: 1080 of 1200 frames processed.\n","[INFO]: 1110 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 30.572858572006226 s\n","[INFO]: 1140 of 1200 frames processed.\n","[INFO]: 1170 of 1200 frames processed.\n","[INFO]: 1200 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 12.812246322631836 s\n","[INFO]: Total time spend in procedure: 10.118572473526001 s\n","[INFO]: 30 of 900 frames processed.\n","[INFO]: 60 of 900 frames processed.\n","[INFO]: 90 of 900 frames processed.\n","[INFO]: 120 of 900 frames processed.\n","[INFO]: 150 of 900 frames processed.\n","[INFO]: 180 of 900 frames processed.\n","[INFO]: 210 of 900 frames processed.\n","[INFO]: 240 of 900 frames processed.\n","[INFO]: 270 of 900 frames processed.\n","[INFO]: 300 of 900 frames processed.\n","[INFO]: 330 of 900 frames processed.\n","[INFO]: 360 of 900 frames processed.\n","[INFO]: 390 of 900 frames processed.\n","[INFO]: 420 of 900 frames processed.\n","[INFO]: 450 of 900 frames processed.\n","[INFO]: 480 of 900 frames processed.\n","[INFO]: 510 of 900 frames processed.\n","[INFO]: 540 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 26.199814558029175 s\n","[INFO]: 570 of 900 frames processed.\n","[INFO]: 600 of 900 frames processed.\n","[INFO]: 630 of 900 frames processed.\n","[INFO]: 660 of 900 frames processed.\n","[INFO]: 690 of 900 frames processed.\n","[INFO]: 720 of 900 frames processed.\n","[INFO]: 750 of 900 frames processed.\n","[INFO]: 780 of 900 frames processed.\n","[INFO]: 810 of 900 frames processed.\n","[INFO]: 840 of 900 frames processed.\n","[INFO]: 870 of 900 frames processed.\n","[INFO]: 900 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 20.63170623779297 s\n","[INFO]: Total time spend in procedure: 7.645118951797485 s\n","[INFO]: 30 of 236 frames processed.\n","[INFO]: 60 of 236 frames processed.\n","[INFO]: 90 of 236 frames processed.\n","[INFO]: 120 of 236 frames processed.\n","[INFO]: 150 of 236 frames processed.\n","[INFO]: 180 of 236 frames processed.\n","[INFO]: 210 of 236 frames processed.\n","[INFO]: Total time spend in procedure: 10.528506755828857 s\n","[INFO]: Total time spend in procedure: 1.6792550086975098 s\n","[INFO]: 30 of 146 frames processed.\n","[INFO]: 60 of 146 frames processed.\n","[INFO]: 90 of 146 frames processed.\n","[INFO]: 120 of 146 frames processed.\n","[INFO]: Total time spend in procedure: 6.905118703842163 s\n","[INFO]: Total time spend in procedure: 1.4625859260559082 s\n","[INFO]: 30 of 74 frames processed.\n","[INFO]: 60 of 74 frames processed.\n","[INFO]: Total time spend in procedure: 3.3424134254455566 s\n","[INFO]: 30 of 86 frames processed.\n","[INFO]: 60 of 86 frames processed.\n","[INFO]: Total time spend in procedure: 3.9410500526428223 s\n","[INFO]: Total time spend in procedure: 0.8689625263214111 s\n","[INFO]: 30 of 160 frames processed.\n","[INFO]: 60 of 160 frames processed.\n","[INFO]: 90 of 160 frames processed.\n","[INFO]: 120 of 160 frames processed.\n","[INFO]: 150 of 160 frames processed.\n","[INFO]: Total time spend in procedure: 7.4240100383758545 s\n","[INFO]: Total time spend in procedure: 1.5037562847137451 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.421109437942505 s\n","[INFO]: Total time spend in procedure: 1.5193698406219482 s\n","[INFO]: 30 of 40 frames processed.\n","[INFO]: Total time spend in procedure: 1.7838928699493408 s\n","[INFO]: 30 of 110 frames processed.\n","[INFO]: 60 of 110 frames processed.\n","[INFO]: 90 of 110 frames processed.\n","[INFO]: Total time spend in procedure: 5.12250542640686 s\n","[INFO]: Total time spend in procedure: 1.128530502319336 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.495427370071411 s\n","[INFO]: Total time spend in procedure: 1.5584290027618408 s\n","[INFO]: 30 of 900 frames processed.\n","[INFO]: 60 of 900 frames processed.\n","[INFO]: 90 of 900 frames processed.\n","[INFO]: 120 of 900 frames processed.\n","[INFO]: 150 of 900 frames processed.\n","[INFO]: 180 of 900 frames processed.\n","[INFO]: 210 of 900 frames processed.\n","[INFO]: 240 of 900 frames processed.\n","[INFO]: 270 of 900 frames processed.\n","[INFO]: 300 of 900 frames processed.\n","[INFO]: 330 of 900 frames processed.\n","[INFO]: 360 of 900 frames processed.\n","[INFO]: 390 of 900 frames processed.\n","[INFO]: 420 of 900 frames processed.\n","[INFO]: 450 of 900 frames processed.\n","[INFO]: 480 of 900 frames processed.\n","[INFO]: 510 of 900 frames processed.\n","[INFO]: 540 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 26.128592252731323 s\n","[INFO]: 570 of 900 frames processed.\n","[INFO]: 600 of 900 frames processed.\n","[INFO]: 630 of 900 frames processed.\n","[INFO]: 660 of 900 frames processed.\n","[INFO]: 690 of 900 frames processed.\n","[INFO]: 720 of 900 frames processed.\n","[INFO]: 750 of 900 frames processed.\n","[INFO]: 780 of 900 frames processed.\n","[INFO]: 810 of 900 frames processed.\n","[INFO]: 840 of 900 frames processed.\n","[INFO]: 870 of 900 frames processed.\n","[INFO]: 900 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 20.738166332244873 s\n","[INFO]: Total time spend in procedure: 7.811867952346802 s\n","[INFO]: 30 of 240 frames processed.\n","[INFO]: 60 of 240 frames processed.\n","[INFO]: 90 of 240 frames processed.\n","[INFO]: 120 of 240 frames processed.\n","[INFO]: 150 of 240 frames processed.\n","[INFO]: 180 of 240 frames processed.\n","[INFO]: 210 of 240 frames processed.\n","[INFO]: 240 of 240 frames processed.\n","[INFO]: Total time spend in procedure: 11.460821866989136 s\n","[INFO]: Total time spend in procedure: 2.3690850734710693 s\n","[INFO]: 30 of 750 frames processed.\n","[INFO]: 60 of 750 frames processed.\n","[INFO]: 90 of 750 frames processed.\n","[INFO]: 120 of 750 frames processed.\n","[INFO]: 150 of 750 frames processed.\n","[INFO]: 180 of 750 frames processed.\n","[INFO]: 210 of 750 frames processed.\n","[INFO]: 240 of 750 frames processed.\n","[INFO]: 270 of 750 frames processed.\n","[INFO]: 300 of 750 frames processed.\n","[INFO]: 330 of 750 frames processed.\n","[INFO]: 360 of 750 frames processed.\n","[INFO]: 390 of 750 frames processed.\n","[INFO]: 420 of 750 frames processed.\n","[INFO]: 450 of 750 frames processed.\n","[INFO]: 480 of 750 frames processed.\n","[INFO]: 510 of 750 frames processed.\n","[INFO]: 540 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 26.011441230773926 s\n","[INFO]: 570 of 750 frames processed.\n","[INFO]: 600 of 750 frames processed.\n","[INFO]: 630 of 750 frames processed.\n","[INFO]: 660 of 750 frames processed.\n","[INFO]: 690 of 750 frames processed.\n","[INFO]: 720 of 750 frames processed.\n","[INFO]: 750 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 13.44432020187378 s\n","[INFO]: Total time spend in procedure: 6.454806089401245 s\n","[INFO]: 30 of 990 frames processed.\n","[INFO]: 60 of 990 frames processed.\n","[INFO]: 90 of 990 frames processed.\n","[INFO]: 120 of 990 frames processed.\n","[INFO]: 150 of 990 frames processed.\n","[INFO]: 180 of 990 frames processed.\n","[INFO]: 210 of 990 frames processed.\n","[INFO]: 240 of 990 frames processed.\n","[INFO]: 270 of 990 frames processed.\n","[INFO]: 300 of 990 frames processed.\n","[INFO]: 330 of 990 frames processed.\n","[INFO]: 360 of 990 frames processed.\n","[INFO]: 390 of 990 frames processed.\n","[INFO]: 420 of 990 frames processed.\n","[INFO]: 450 of 990 frames processed.\n","[INFO]: 480 of 990 frames processed.\n","[INFO]: 510 of 990 frames processed.\n","[INFO]: 540 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 26.23028564453125 s\n","[INFO]: 570 of 990 frames processed.\n","[INFO]: 600 of 990 frames processed.\n","[INFO]: 630 of 990 frames processed.\n","[INFO]: 660 of 990 frames processed.\n","[INFO]: 690 of 990 frames processed.\n","[INFO]: 720 of 990 frames processed.\n","[INFO]: 750 of 990 frames processed.\n","[INFO]: 780 of 990 frames processed.\n","[INFO]: 810 of 990 frames processed.\n","[INFO]: 840 of 990 frames processed.\n","[INFO]: 870 of 990 frames processed.\n","[INFO]: 900 of 990 frames processed.\n","[INFO]: 930 of 990 frames processed.\n","[INFO]: 960 of 990 frames processed.\n","[INFO]: 990 of 990 frames processed.\n","[INFO]: Total time spend in procedure: 25.279950857162476 s\n","[INFO]: Total time spend in procedure: 8.857688426971436 s\n","[INFO]: 30 of 236 frames processed.\n","[INFO]: 60 of 236 frames processed.\n","[INFO]: 90 of 236 frames processed.\n","[INFO]: 120 of 236 frames processed.\n","[INFO]: 150 of 236 frames processed.\n","[INFO]: 180 of 236 frames processed.\n","[INFO]: 210 of 236 frames processed.\n","[INFO]: Total time spend in procedure: 10.655874490737915 s\n","[INFO]: Total time spend in procedure: 1.739337682723999 s\n","[INFO]: 30 of 600 frames processed.\n","[INFO]: 60 of 600 frames processed.\n","[INFO]: 90 of 600 frames processed.\n","[INFO]: 120 of 600 frames processed.\n","[INFO]: 150 of 600 frames processed.\n","[INFO]: 180 of 600 frames processed.\n","[INFO]: 210 of 600 frames processed.\n","[INFO]: 240 of 600 frames processed.\n","[INFO]: 270 of 600 frames processed.\n","[INFO]: 300 of 600 frames processed.\n","[INFO]: 330 of 600 frames processed.\n","[INFO]: 360 of 600 frames processed.\n","[INFO]: 390 of 600 frames processed.\n","[INFO]: 420 of 600 frames processed.\n","[INFO]: 450 of 600 frames processed.\n","[INFO]: 480 of 600 frames processed.\n","[INFO]: 510 of 600 frames processed.\n","[INFO]: 540 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 26.174591064453125 s\n","[INFO]: 570 of 600 frames processed.\n","[INFO]: 600 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 6.6607935428619385 s\n","[INFO]: 30 of 1200 frames processed.\n","[INFO]: 60 of 1200 frames processed.\n","[INFO]: 90 of 1200 frames processed.\n","[INFO]: 120 of 1200 frames processed.\n","[INFO]: 150 of 1200 frames processed.\n","[INFO]: 180 of 1200 frames processed.\n","[INFO]: 210 of 1200 frames processed.\n","[INFO]: 240 of 1200 frames processed.\n","[INFO]: 270 of 1200 frames processed.\n","[INFO]: 300 of 1200 frames processed.\n","[INFO]: 330 of 1200 frames processed.\n","[INFO]: 360 of 1200 frames processed.\n","[INFO]: 390 of 1200 frames processed.\n","[INFO]: 420 of 1200 frames processed.\n","[INFO]: 450 of 1200 frames processed.\n","[INFO]: 480 of 1200 frames processed.\n","[INFO]: 510 of 1200 frames processed.\n","[INFO]: 540 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 25.999128818511963 s\n","[INFO]: 570 of 1200 frames processed.\n","[INFO]: 600 of 1200 frames processed.\n","[INFO]: 630 of 1200 frames processed.\n","[INFO]: 660 of 1200 frames processed.\n","[INFO]: 690 of 1200 frames processed.\n","[INFO]: 720 of 1200 frames processed.\n","[INFO]: 750 of 1200 frames processed.\n","[INFO]: 780 of 1200 frames processed.\n","[INFO]: 810 of 1200 frames processed.\n","[INFO]: 840 of 1200 frames processed.\n","[INFO]: 870 of 1200 frames processed.\n","[INFO]: 900 of 1200 frames processed.\n","[INFO]: 930 of 1200 frames processed.\n","[INFO]: 960 of 1200 frames processed.\n","[INFO]: 990 of 1200 frames processed.\n","[INFO]: 1020 of 1200 frames processed.\n","[INFO]: 1050 of 1200 frames processed.\n","[INFO]: 1080 of 1200 frames processed.\n","[INFO]: 1110 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 30.581146001815796 s\n","[INFO]: 1140 of 1200 frames processed.\n","[INFO]: 1170 of 1200 frames processed.\n","[INFO]: 1200 of 1200 frames processed.\n","[INFO]: Total time spend in procedure: 12.832910060882568 s\n","[INFO]: Total time spend in procedure: 9.941676139831543 s\n","[INFO]: 30 of 780 frames processed.\n","[INFO]: 60 of 780 frames processed.\n","[INFO]: 90 of 780 frames processed.\n","[INFO]: 120 of 780 frames processed.\n","[INFO]: 150 of 780 frames processed.\n","[INFO]: 180 of 780 frames processed.\n","[INFO]: 210 of 780 frames processed.\n","[INFO]: 240 of 780 frames processed.\n","[INFO]: 270 of 780 frames processed.\n","[INFO]: 300 of 780 frames processed.\n","[INFO]: 330 of 780 frames processed.\n","[INFO]: 360 of 780 frames processed.\n","[INFO]: 390 of 780 frames processed.\n","[INFO]: 420 of 780 frames processed.\n","[INFO]: 450 of 780 frames processed.\n","[INFO]: 480 of 780 frames processed.\n","[INFO]: 510 of 780 frames processed.\n","[INFO]: 540 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 26.070196390151978 s\n","[INFO]: 570 of 780 frames processed.\n","[INFO]: 600 of 780 frames processed.\n","[INFO]: 630 of 780 frames processed.\n","[INFO]: 660 of 780 frames processed.\n","[INFO]: 690 of 780 frames processed.\n","[INFO]: 720 of 780 frames processed.\n","[INFO]: 750 of 780 frames processed.\n","[INFO]: 780 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 15.044441223144531 s\n","[INFO]: Total time spend in procedure: 6.763350248336792 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.488763093948364 s\n","[INFO]: Total time spend in procedure: 1.5321757793426514 s\n","[INFO]: 30 of 160 frames processed.\n","[INFO]: 60 of 160 frames processed.\n","[INFO]: 90 of 160 frames processed.\n","[INFO]: 120 of 160 frames processed.\n","[INFO]: 150 of 160 frames processed.\n","[INFO]: Total time spend in procedure: 7.427222490310669 s\n","[INFO]: Total time spend in procedure: 1.49819016456604 s\n","[INFO]: 30 of 74 frames processed.\n","[INFO]: 60 of 74 frames processed.\n","[INFO]: Total time spend in procedure: 3.3671882152557373 s\n","[INFO]: 30 of 40 frames processed.\n","[INFO]: Total time spend in procedure: 1.7928147315979004 s\n","[INFO]: 30 of 86 frames processed.\n","[INFO]: 60 of 86 frames processed.\n","[INFO]: Total time spend in procedure: 3.9530856609344482 s\n","[INFO]: Total time spend in procedure: 0.8754425048828125 s\n","[INFO]: 30 of 162 frames processed.\n","[INFO]: 60 of 162 frames processed.\n","[INFO]: 90 of 162 frames processed.\n","[INFO]: 120 of 162 frames processed.\n","[INFO]: 150 of 162 frames processed.\n","[INFO]: Total time spend in procedure: 7.488012075424194 s\n","[INFO]: Total time spend in procedure: 1.5488994121551514 s\n","[INFO]: 30 of 110 frames processed.\n","[INFO]: 60 of 110 frames processed.\n","[INFO]: 90 of 110 frames processed.\n","[INFO]: Total time spend in procedure: 5.1134538650512695 s\n","[INFO]: Total time spend in procedure: 1.1335954666137695 s\n","[INFO]: 30 of 146 frames processed.\n","[INFO]: 60 of 146 frames processed.\n","[INFO]: 90 of 146 frames processed.\n","[INFO]: 120 of 146 frames processed.\n","[INFO]: Total time spend in procedure: 6.806366443634033 s\n","[INFO]: Total time spend in procedure: 1.4717402458190918 s\n","[INFO]: 30 of 750 frames processed.\n","[INFO]: 60 of 750 frames processed.\n","[INFO]: 90 of 750 frames processed.\n","[INFO]: 120 of 750 frames processed.\n","[INFO]: 150 of 750 frames processed.\n","[INFO]: 180 of 750 frames processed.\n","[INFO]: 210 of 750 frames processed.\n","[INFO]: 240 of 750 frames processed.\n","[INFO]: 270 of 750 frames processed.\n","[INFO]: 300 of 750 frames processed.\n","[INFO]: 330 of 750 frames processed.\n","[INFO]: 360 of 750 frames processed.\n","[INFO]: 390 of 750 frames processed.\n","[INFO]: 420 of 750 frames processed.\n","[INFO]: 450 of 750 frames processed.\n","[INFO]: 480 of 750 frames processed.\n","[INFO]: 510 of 750 frames processed.\n","[INFO]: 540 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 25.934600830078125 s\n","[INFO]: 570 of 750 frames processed.\n","[INFO]: 600 of 750 frames processed.\n","[INFO]: 630 of 750 frames processed.\n","[INFO]: 660 of 750 frames processed.\n","[INFO]: 690 of 750 frames processed.\n","[INFO]: 720 of 750 frames processed.\n","[INFO]: 750 of 750 frames processed.\n","[INFO]: Total time spend in procedure: 13.407138347625732 s\n","[INFO]: Total time spend in procedure: 6.442163944244385 s\n","[INFO]: 30 of 240 frames processed.\n","[INFO]: 60 of 240 frames processed.\n","[INFO]: 90 of 240 frames processed.\n","[INFO]: 120 of 240 frames processed.\n","[INFO]: 150 of 240 frames processed.\n","[INFO]: 180 of 240 frames processed.\n","[INFO]: 210 of 240 frames processed.\n","[INFO]: 240 of 240 frames processed.\n","[INFO]: Total time spend in procedure: 11.476852178573608 s\n","[INFO]: Total time spend in procedure: 2.351994037628174 s\n","[INFO]: 30 of 236 frames processed.\n","[INFO]: 60 of 236 frames processed.\n","[INFO]: 90 of 236 frames processed.\n","[INFO]: 120 of 236 frames processed.\n","[INFO]: 150 of 236 frames processed.\n","[INFO]: 180 of 236 frames processed.\n","[INFO]: 210 of 236 frames processed.\n","[INFO]: Total time spend in procedure: 10.575950384140015 s\n","[INFO]: Total time spend in procedure: 1.661329746246338 s\n","[INFO]: 30 of 780 frames processed.\n","[INFO]: 60 of 780 frames processed.\n","[INFO]: 90 of 780 frames processed.\n","[INFO]: 120 of 780 frames processed.\n","[INFO]: 150 of 780 frames processed.\n","[INFO]: 180 of 780 frames processed.\n","[INFO]: 210 of 780 frames processed.\n","[INFO]: 240 of 780 frames processed.\n","[INFO]: 270 of 780 frames processed.\n","[INFO]: 300 of 780 frames processed.\n","[INFO]: 330 of 780 frames processed.\n","[INFO]: 360 of 780 frames processed.\n","[INFO]: 390 of 780 frames processed.\n","[INFO]: 420 of 780 frames processed.\n","[INFO]: 450 of 780 frames processed.\n","[INFO]: 480 of 780 frames processed.\n","[INFO]: 510 of 780 frames processed.\n","[INFO]: 540 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 26.045958280563354 s\n","[INFO]: 570 of 780 frames processed.\n","[INFO]: 600 of 780 frames processed.\n","[INFO]: 630 of 780 frames processed.\n","[INFO]: 660 of 780 frames processed.\n","[INFO]: 690 of 780 frames processed.\n","[INFO]: 720 of 780 frames processed.\n","[INFO]: 750 of 780 frames processed.\n","[INFO]: 780 of 780 frames processed.\n","[INFO]: Total time spend in procedure: 14.891957521438599 s\n","[INFO]: Total time spend in procedure: 6.7082648277282715 s\n","[INFO]: 30 of 600 frames processed.\n","[INFO]: 60 of 600 frames processed.\n","[INFO]: 90 of 600 frames processed.\n","[INFO]: 120 of 600 frames processed.\n","[INFO]: 150 of 600 frames processed.\n","[INFO]: 180 of 600 frames processed.\n","[INFO]: 210 of 600 frames processed.\n","[INFO]: 240 of 600 frames processed.\n","[INFO]: 270 of 600 frames processed.\n","[INFO]: 300 of 600 frames processed.\n","[INFO]: 330 of 600 frames processed.\n","[INFO]: 360 of 600 frames processed.\n","[INFO]: 390 of 600 frames processed.\n","[INFO]: 420 of 600 frames processed.\n","[INFO]: 450 of 600 frames processed.\n","[INFO]: 480 of 600 frames processed.\n","[INFO]: 510 of 600 frames processed.\n","[INFO]: 540 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 26.006078243255615 s\n","[INFO]: 570 of 600 frames processed.\n","[INFO]: 600 of 600 frames processed.\n","[INFO]: Total time spend in procedure: 6.573444843292236 s\n","[INFO]: 30 of 900 frames processed.\n","[INFO]: 60 of 900 frames processed.\n","[INFO]: 90 of 900 frames processed.\n","[INFO]: 120 of 900 frames processed.\n","[INFO]: 150 of 900 frames processed.\n","[INFO]: 180 of 900 frames processed.\n","[INFO]: 210 of 900 frames processed.\n","[INFO]: 240 of 900 frames processed.\n","[INFO]: 270 of 900 frames processed.\n","[INFO]: 300 of 900 frames processed.\n","[INFO]: 330 of 900 frames processed.\n","[INFO]: 360 of 900 frames processed.\n","[INFO]: 390 of 900 frames processed.\n","[INFO]: 420 of 900 frames processed.\n","[INFO]: 450 of 900 frames processed.\n","[INFO]: 480 of 900 frames processed.\n","[INFO]: 510 of 900 frames processed.\n","[INFO]: 540 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 26.170116901397705 s\n","[INFO]: 570 of 900 frames processed.\n","[INFO]: 600 of 900 frames processed.\n","[INFO]: 630 of 900 frames processed.\n","[INFO]: 660 of 900 frames processed.\n","[INFO]: 690 of 900 frames processed.\n","[INFO]: 720 of 900 frames processed.\n","[INFO]: 750 of 900 frames processed.\n","[INFO]: 780 of 900 frames processed.\n","[INFO]: 810 of 900 frames processed.\n","[INFO]: 840 of 900 frames processed.\n","[INFO]: 870 of 900 frames processed.\n","[INFO]: 900 of 900 frames processed.\n","[INFO]: Total time spend in procedure: 20.597590923309326 s\n","[INFO]: Total time spend in procedure: 7.654884338378906 s\n","[INFO]: 30 of 990 frames processed.\n","[INFO]: 60 of 990 frames processed.\n","[INFO]: 90 of 990 frames processed.\n","[INFO]: 120 of 990 frames processed.\n","[INFO]: 150 of 990 frames processed.\n","[INFO]: 180 of 990 frames processed.\n","[INFO]: 210 of 990 frames processed.\n","[INFO]: 240 of 990 frames processed.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"01px-RNbmc5T"},"source":["def loss_plot(losses):\n","    for phase in [\"train\", \"valid\"]:\n","        plt.plot(range(1, len(losses[phase]) + 1), losses[phase], label = phase + \" losses\")\n","    plt.legend(prop = {'size': 10})\n","    plt.title('loss function', size = 10)\n","    plt.xlabel('epoch', size = 10); plt.ylabel('loss value', size = 10)\n","\n","loss_plot(EDCLSTM_stats[\"losses\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-yBJgw9A-nIm"},"source":["def test_metrics(model, video_list, criterion, np, nf): # Metricas\n","    running_loss = 0.0\n","    for video_path in video_list: # Start for\n","        loss = train_step(model, criterion, video_path = video_path, \n","                          n_past_step = np, n_fut_step = nf, \n","                          batch_size = None, resize = (720,480), fps = 150)\n","        if loss is not None: running_loss += loss\n","    running_loss /= len(video_list)\n","    output.clear()\n","    print(\"[INFO] Loss in dataset:\", running_loss)\n","\n","test_metrics(EDCLSTM_model, videoloaders[\"test\"], criterion, np = n_steps_past, nf = n_steps_fut)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bH8nYS8ZApvD"},"source":["''' Draw humans in video  with detection'''\n","def video_prediction(model, video_in, step_past, fps = None, video_out_path = None, force_mp4 = True,\n","                  total_frames = None, skip_frames = None, resize = None, \n","                  background = True, print_im = False):\n","    # Read video properties\n","    video_w, video_h, video_fps, video_codec, video_size = video_prop_read(video_in, force_mp4)\n","    video = cv2.VideoCapture(video_in)\n","\n","    # Video object to save and video_in read\n","    if fps is not None and fps < video_fps: video_fps = fps\n","    if video_out_path is not None:\n","        video_out_path, ext = os.path.splitext(video_out_path)\n","        if force_mp4: video_out_path += \".mp4\"\n","        elif len(ext) == 0: video_out_path += os.path.splitext(video_in)[-1]\n","        else: video_out_path += ext\n","        if resize is not None: video_w, video_h = resize\n","        video_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*video_codec), \n","                                    video_fps, (video_w, video_h))\n","        print(\"[INFO]: Video will be saved in\", video_out_path)\n","\n","    fcount = 0; tic = time.time(); total_paf = []; total_heat = []; rcount = 0\n","    model.eval()\n","    while video.isOpened():\n","        ret, frame = video.read(); fcount += 1\n","        if fps is not None and fcount % (fps//video_fps) != 0: continue # Skip frames\n","        rcount += 1\n","        if skip_frames is not None and rcount <= skip_frames : continue # Skip frames\n","        if (cv2.waitKey(1) & 0xFF == ord('q')) or not ret: break # End of video\n","\n","        # Detection process\n","        if len(total_paf) < step_past:\n","            paf, heatmap, _ = im_forward(frame, rtpose_model) # CNN maps\n","            total_paf += [paf]; total_heat += [heatmap]; # Concat detections\n","            # plt.hist(paf.flatten(), bins = 12); plt.hist(heatmap.flatten(), bins = 12); \n","            # plt.show()\n","        else:\n","            paf_i, heatmap_i, _ = im_forward(frame, rtpose_model) # CNN maps\n","            with torch.set_grad_enabled(False):\n","                x_paf = torch.from_numpy(np.stack(total_paf, axis = 0)[None]).cuda().permute(0,1,4,2,3) # to (B,sp,C,H,W)\n","                x_heat = torch.from_numpy(np.stack(total_heat, axis = 0)[None]).cuda().permute(0,1,4,2,3) # to (B,sp,C,H,W)\n","                paf, heatmap = model([x_paf, x_heat], n_step_fut = 1) # Only one future prediction\n","                paf = paf.squeeze().permute(1,2,0).cpu().detach().numpy() # Size of (H,W,C)\n","                heatmap = heatmap.squeeze().permute(1,2,0).cpu().detach().numpy() # Size of (H,W,C)\n","            total_paf += [paf]; total_heat += [heatmap]; # Concat detections\n","            # total_paf = total_paf[-step_past:]; total_heat = total_heat[-step_past:]\n","            mse = (np.square(paf - paf)).sum(axis=None)\n","            print(\"[INFO]: MSE = \", mse)\n","        \n","        # Save pose-detection in video_out\n","        if video_out_path is not None or print_im:\n","            humans = paf_to_pose_cpp(heatmap, paf, cfg)\n","            if not background: frame = np.zeros(frame.shape, dtype = \"uint8\")\n","            frame_out = draw_humans(frame, humans)\n","            if resize is not None: frame_out = cv2.resize(frame_out, resize)\n","            if video_out_path is not None: video_out.write(frame_out)\n","        \n","        # if isprogrammer: cv2.imshow(\"output.mp4\", frame)\n","        if fcount % 1 == 0:\n","            print(\"[INFO]: {} of {} frames processed.\".format(fcount, video_size))\n","            if print_im: \n","                plt.imshow(cv2.cvtColor(frame_out, cv2.COLOR_BGR2RGB))\n","                plt.axis(\"off\"); plt.show()\n","        \n","        if total_frames is not None and rcount >= total_frames: break # End\n","        \n","    video.release()\n","    if video_out_path is not None: \n","        video_out.release()\n","        if \"mp4\" in os.path.splitext(video_out_path)[-1]:\n","            video_out_path_compress = video_out_path.replace(\".mp4\",\"_out.mp4\")\n","            !sudo ffmpeg -t 5 -i \"$video_out_path\" \"$video_out_path_compress\" # Compress\n","            !mv \"$video_out_path_compress\" \"$video_out_path\"\n","            !rm \"$video_out_path_compress\"\n","            output.clear()\n","        print(\"[INFO]: Video saved successfully\")\n","    print(\"[INFO]: Total time spend in procedure:\", time.time() - tic, \"s\")\n","    if len(total_paf) == 0: return None, None\n","    else: return np.stack(total_paf, axis = 0), np.stack(total_heat, axis = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1HXMGZYGeGM"},"source":["video_path_proof = \"./data/Videos_Deep_MiosHAHA/Entrenamiento/Original1_Train.mp4\"\n","demo_pred2 = video_prediction(EDCLSTM_model, video_path_proof, step_past = n_steps_past, \n","                              resize = (720,480), fps = 150, background = True, skip_frames = 6,\n","                              print_im = True)\n","print(demo_pred2[0].shape, demo_pred2[1].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GuGuIP6j7dc9"},"source":["## ***Anexos: GitHub connection***\n","Here, some functions to upload the github respository"]},{"cell_type":"code","metadata":{"id":"XM88fGToxGPB"},"source":["''' Function definitions'''\n","# Git pull\n","def git_pull(repo_pwd, show_current_branch = False, make_commit = False): # Only for colab space work\n","    global user_git, email_git\n","    import sys\n","    IN_COLAB = 'google.colab' in sys.modules\n","    if IN_COLAB:\n","        from google.colab import drive\n","        drive.mount('/content/gdrive')\n","\n","        %cd \"$repo_pwd\"\n","        # !git config --list\n","        if show_current_branch: \n","            !git branch \n","        if make_commit:\n","            if \"user_git\" not in globals(): user_git = input(\"User github?: \")\n","            if \"email_git\" not in globals(): email_git = input(\"Email github?: \") \n","            !git config --global user.email \"$email_git\"\n","            !git config --global user.name \"$user_git\"\n","            !git commit -am \"Updating in colab\"\n","        !git pull\n","        !git status\n","    else:\n","        print(\"[INFO] You are not in collaboration, nothing has been done.\")\n","\n","# Git push\n","def git_push(repo_pwd): # Only for colab space work\n","    global user_git, email_git\n","    import sys\n","    IN_COLAB = 'google.colab' in sys.modules\n","    if IN_COLAB:\n","        from google.colab import drive\n","        import getpass\n","        drive.mount('/content/gdrive')\n","\n","        %cd \"$repo_pwd\"\n","        if \"user_git\" not in globals(): user_git = input(\"User github?: \")\n","        if \"email_git\" not in globals(): email_git = input(\"Email github?: \")\n","\n","        # Password login\n","        try: \n","            pwd_git = getpass.getpass(prompt='{} github password: '.format(user_git)) \n","        except Exception as error: \n","            print('ERROR', error) \n","\n","        # Upload from every where\n","        origin_git = !git config --get remote.origin.url\n","        origin_git = origin_git[0].replace(\"https://\",\"https://{}:{}@\".format(user_git,pwd_git))\n","\n","        !git config --global user.email \"$email_git\"\n","        !git config --global user.name \"$user_git\"\n","        !git status\n","\n","        x = \" \"\n","        while x.lower() != \"y\" and x.lower() != \"n\": x = input(\"Continue?...[y/n]: \")\n","\n","        if x.lower() == \"y\":\n","            com_message = input(\"Enter the commit message: \")\n","            !git add .\n","            !git commit -am \"$com_message\"\n","            !git push \"$origin\"\n","            !git status\n","    else:\n","        print(\"[INFO] You are not in collaboration, nothing has been done.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOTNnyQsDfXb"},"source":["repo_pwd = \"/content/gdrive/My Drive/Colab Notebooks/RT-multiperson-pose-pytorch\"\n","# git_pull(repo_pwd, show_current_branch = False, make_commit = True)\n","# git_push(repo_pwd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GY2pPGvf8bad"},"source":[""],"execution_count":null,"outputs":[]}]}